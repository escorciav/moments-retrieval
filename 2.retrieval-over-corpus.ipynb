{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Retrieval over corpus\n",
    "Compute pdist2\n",
    "\n",
    "- Extract features from MCN\n",
    "\n",
    "    `bash dump_features.sh`\n",
    "    \n",
    "- Move features\n",
    "\n",
    "    `mv ../localizing-moments/results/*.hdf5 data/interim/mcn/features/`\n",
    "\n",
    "- Class to parse and interact with corpus\n",
    "    - ~~reading hdf5~~\n",
    "    - ~~make dictionary~~\n",
    "    - ~~~make corpus matrix~~\n",
    "    - ~~Method to return video and segment~~\n",
    "    - ~~grab possible segments~~\n",
    "\n",
    "- Compute distance and retrieve sorted samples for a given vector query\n",
    "    - optional: batch computation\n",
    "\n",
    "- Task a\n",
    "    - ~~data structure for ground-truth.~~\n",
    "\n",
    "- The __outcome__ of this task are/is:\n",
    "    - module `corpus.py`\n",
    "    - class `Queries` in new module `dataset.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18339 (873, 6)\n",
      "simple test\n",
      "Traceback (most recent call last):\n",
      "  File \"didemo.py\", line 250, in <module>\n",
      "    dataset = Didemo(data, cues)\n",
      "  File \"didemo.py\", line 47, in __init__\n",
      "    self.lang_interface = LanguageRepresentationMCN(max_words)\n",
      "  File \"didemo.py\", line 197, in __init__\n",
      "    self.rec_embedding = RecurrentEmbedding()\n",
      "  File \"/mnt/ilcompf9d1/user/escorcia/moments-retrieval/glove.py\", line 35, in __init__\n",
      "    vocab = open(vocab_file).readlines()\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/raw/vocab_glove_complete.txt'\n"
     ]
    }
   ],
   "source": [
    "!python corpus.py\n",
    "!python didemo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpus import Corpus\n",
    "from dataset import Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Implement evaluation code\n",
    "\n",
    "The metric should reflect the probability of finding a relevant moment, clip inside a video, for a given query `q` among `k` possible moments in the entire corpus.\n",
    "\n",
    "Given that he have multiple annotations per query inside the same video (accounting for inherent temporal ambiguity), we need a \"concensus\" or \"thresholding\" criteria to assess that a given clip is relevant among a pool of annotations.\n",
    "\n",
    "Note: This is not related to the tIOU threshold. Only a single, golden, annotation would circumvent this problem.\n",
    "\n",
    "Concensus - thresholding strategies:\n",
    "- max. Assigns a true if the prediction match any annotation.\n",
    "Makes problem easier as the chance increases proportionally to ambiguity of query. It's sensitive to outliers in annotation process. Probably relevant for tIOU.\n",
    "\n",
    "Metrics\n",
    "\n",
    "- R@k,c\n",
    "\n",
    "    prob of finding a moment on `top-k`.\n",
    "    Here, the moment is relevant when its average rank on the best 3 out of 4 annotations is lower or equal than `j`.\n",
    "\n",
    "- mIOU\n",
    "\n",
    "   \n",
    "- mRank\n",
    "    mean rank.\n",
    "\n",
    "\n",
    "~~Among the thresholding strategies, we have:~~\n",
    "\n",
    "~~- average. Makes problem harder as it forces to agree with multiple annotators. It's also sensitive to outliers.~~\n",
    "\n",
    "~~- average over a subset of annotations. As above but accounting for outliers.~~\n",
    "\n",
    "~~Thresholding implies to compute a given metric a measure the~~\n",
    "~~For consistency with DiDeMo standard, we opt for thresholding:~~\n",
    "\n",
    "Implementation note: given multiple annotations for each query is not conveninent to deal with the raw indexes from the feature matrix. Moreover, those indexes would be useless for considering tIOU. Hopefully, we have a function to invert those indexes into video and segment indexes. However, we need to keep consistency in the list of videos and segments to make an apple 2 apple comparsion.\n",
    "\n",
    "Evaluation pseudo-code\n",
    "\n",
    "```\n",
    "inputs: list of queries; ground-truth, k\n",
    "\n",
    "recall_at_k = []\n",
    "miou = []\n",
    "for each query:\n",
    "    get vector\n",
    "    compute distance and return sorted list of indexes\n",
    "    # prediction would end here\n",
    "    # code for server could continue to provide more info.\n",
    "    # like red to miss and green for hit ;)\n",
    "    \n",
    "    # evaluation\n",
    "    for i in range(k)\n",
    "        if video_idx[i] == gt[query][video_idx]:\n",
    "            check if it's the segment we are looking for\n",
    "            miou.append()\n",
    "        else:\n",
    "            miou.append(0)\n",
    "\n",
    "sum(recall_at_k) / len(recall_at_k)\n",
    "sum(miou_at_k) / len(miou_at_k)\n",
    "```\n",
    "\n",
    "TODO: what is the average iou in this case? max/mean - average_iou\n",
    "\n",
    "DiDeMo evaluation\n",
    "\n",
    "```python\n",
    "average_ranks = []\n",
    "average_iou = []\n",
    "for s, d in zip(segments, data):\n",
    "  pred = s[0]\n",
    "  ious = [iou(pred, t) for t in d['times']]\n",
    "  average_iou.append(np.mean(np.sort(ious)[-3:]))\n",
    "  ranks = [rank(s, t) for t in d['times']]\n",
    "  average_ranks.append(np.mean(np.sort(ranks)[:3]))\n",
    "rank1 = np.sum(np.array(average_ranks) <= 1)/float(len(average_ranks))\n",
    "rank5 = np.sum(np.array(average_ranks) <= 5)/float(len(average_ranks))\n",
    "miou = np.mean(average_iou)\n",
    "```\n",
    "\n",
    "- TODO\n",
    "    - weak agreement\n",
    "    - unit-test vs lisa's code\n",
    "    - consistency for indexing. avoid to ???\n",
    "\n",
    "- The __outcome__ of this task is/are:\n",
    "    - the module `np_segments_ops.py`\n",
    "    - the class `RetrievalEvaluation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@(1, 5, 10)=[0.004545454545454545, 0.014114832535885167, 0.027033492822966507];\n",
      "R@(1, 5, 10),0.1=[0.006220095693779904, 0.018660287081339714, 0.03373205741626794];\n",
      "R@(1, 5, 10),didemo=[0.003827751196172249, 0.009330143540669857, 0.01555023923444976];\n",
      "mIOU=0.0043;\n",
      "mRank=1657.46;\n",
      "Elapsed time: 30.823062658309937\n"
     ]
    }
   ],
   "source": [
    "!python np_segments_ops.py\n",
    "!python evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from np_segments_ops import iou as segments_iou\n",
    "from evaluation import RetrievalEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RGB\n",
      "R@(1, 5, 10)=[0.004545454545454545, 0.014114832535885167, 0.027033492822966507];\n",
      "R@(1, 5, 10),0.75=[0.004545454545454545, 0.014114832535885167, 0.027033492822966507];\n",
      "R@(1, 5, 10),didemo=[0.003827751196172249, 0.009330143540669857, 0.01555023923444976];\n",
      "mIOU=0.0043;\n",
      "mRank=1657.46;\n",
      "Elapsed time: 29.125818014144897\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "val_rgb_corpus = 'data/interim/mcn/features/corpus_val.hdf5'\n",
    "val_rgb_queries = 'data/interim/mcn/features/queries_val.hdf5'\n",
    "val_annotations = 'data/raw/val_data.json'\n",
    "val_judge = RetrievalEvaluation(val_rgb_corpus, val_annotations, (1, 5, 10))\n",
    "\n",
    "with h5py.File(val_rgb_queries, 'r') as fid:\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for sample_key, h5ds in fid.items():\n",
    "        query_id = int(sample_key)\n",
    "        query_vector = h5ds[:]\n",
    "        val_judge.eval_single_vector(query_vector, query_id)\n",
    "    performace = val_judge.eval()\n",
    "    print('Validation RGB')\n",
    "    print('R@{0:}={2:};\\nR@{0:},{1:}={3:};\\nR@{0:},didemo={4:};\\n'\n",
    "          'mIOU={5:.4f};\\nmRank={6:.2f};'\n",
    "          .format(val_judge.k, val_judge.iou_threshold,\n",
    "                  *performace))\n",
    "    print('Elapsed time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Flow\n",
      "R@(1, 5, 10)=[0.004545454545454545, 0.01555023923444976, 0.03110047846889952];\n",
      "R@(1, 5, 10),0.75=[0.004545454545454545, 0.01555023923444976, 0.03110047846889952];\n",
      "R@(1, 5, 10),didemo=[0.004784688995215311, 0.00909090909090909, 0.016507177033492824];\n",
      "mIOU=0.0045;\n",
      "mRank=1597.16;\n",
      "Elapsed time: 29.787809133529663\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "val_flow_corpus = 'data/interim/mcn/features/corpus_val_flow.hdf5'\n",
    "val_flow_queries = 'data/interim/mcn/features/queries_val_flow.hdf5'\n",
    "val_annotations = 'data/raw/val_data.json'\n",
    "val_judge = RetrievalEvaluation(val_flow_corpus, val_annotations, (1, 5, 10))\n",
    "\n",
    "with h5py.File(val_flow_queries, 'r') as fid:\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for sample_key, h5ds in fid.items():\n",
    "        query_id = int(sample_key)\n",
    "        query_vector = h5ds[:]\n",
    "        val_judge.eval_single_vector(query_vector, query_id)\n",
    "    performace = val_judge.eval()\n",
    "    print('Validation Flow')\n",
    "    print('R@{0:}={2:};\\nR@{0:},{1:}={3:};\\nR@{0:},didemo={4:};\\n'\n",
    "          'mIOU={5:.4f};\\nmRank={6:.2f};'\n",
    "          .format(val_judge.k, val_judge.iou_threshold,\n",
    "                  *performace))\n",
    "    print('Elapsed time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RGB\n",
      "R@(1, 5, 10)=[0.003481720964934096, 0.014175578214374533, 0.02561551852772942];\n",
      "R@(1, 5, 10),0.75=[0.003481720964934096, 0.014175578214374533, 0.02561551852772942];\n",
      "R@(1, 5, 10),didemo=[0.002238249191743347, 0.007212136284506341, 0.014921661278288983];\n",
      "mIOU=0.0028;\n",
      "mRank=1540.61;\n",
      "Elapsed time: 26.918400526046753\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "test_rgb_corpus = 'data/interim/mcn/features/corpus_test.hdf5'\n",
    "test_rgb_queries = 'data/interim/mcn/features/queries_test.hdf5'\n",
    "test_annotations = 'data/raw/test_data.json'\n",
    "test_judge = RetrievalEvaluation(test_rgb_corpus, test_annotations, (1, 5, 10))\n",
    "\n",
    "with h5py.File(test_rgb_queries, 'r') as fid:\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for sample_key, h5ds in fid.items():\n",
    "        query_id = int(sample_key)\n",
    "        query_vector = h5ds[:]\n",
    "        test_judge.eval_single_vector(query_vector, query_id)\n",
    "    performace = test_judge.eval()\n",
    "    print('Test RGB')\n",
    "    print('R@{0:}={2:};\\nR@{0:},{1:}={3:};\\nR@{0:},didemo={4:};\\n'\n",
    "          'mIOU={5:.4f};\\nmRank={6:.2f};'\n",
    "          .format(test_judge.k, test_judge.iou_threshold,\n",
    "                  *performace))\n",
    "    print('Elapsed time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RGB\n",
      "R@(1, 5, 10)=[0.004973887092762994, 0.01840338224322308, 0.030838099975130564];\n",
      "R@(1, 5, 10),0.75=[0.004973887092762994, 0.01840338224322308, 0.030838099975130564];\n",
      "R@(1, 5, 10),didemo=[0.004476498383486694, 0.011937329022631187, 0.01840338224322308];\n",
      "mIOU=0.0046;\n",
      "mRank=1570.50;\n",
      "Elapsed time: 30.41560411453247\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "test_flow_corpus = 'data/interim/mcn/features/corpus_test_flow.hdf5'\n",
    "test_flow_queries = 'data/interim/mcn/features/queries_test_flow.hdf5'\n",
    "test_annotations = 'data/raw/test_data.json'\n",
    "test_judge = RetrievalEvaluation(test_flow_corpus, test_annotations, (1, 5, 10))\n",
    "\n",
    "with h5py.File(test_flow_queries, 'r') as fid:\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for sample_key, h5ds in fid.items():\n",
    "        query_id = int(sample_key)\n",
    "        query_vector = h5ds[:]\n",
    "        test_judge.eval_single_vector(query_vector, query_id)\n",
    "    performace = test_judge.eval()\n",
    "    print('Test Flow')\n",
    "    print('R@{0:}={2:};\\nR@{0:},{1:}={3:};\\nR@{0:},didemo={4:};\\n'\n",
    "          'mIOU={5:.4f};\\nmRank={6:.2f};'\n",
    "          .format(test_judge.k, test_judge.iou_threshold,\n",
    "                  *performace))\n",
    "    print('Elapsed time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intra+inter val rgb\n",
      "R@(1, 5, 10, 100, 1000)=[0.004545454545454545, 0.014114832535885167, 0.027033492822966507, 0.1715311004784689, 0.5937799043062201];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.004545454545454545, 0.014114832535885167, 0.027033492822966507, 0.1715311004784689, 0.5947368421052631];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.003827751196172249, 0.009330143540669857, 0.01555023923444976, 0.10047846889952153, 0.45382775119617225];\n",
      "mIOU=0.0043;\n",
      "mRank=1657.46;\n",
      "intra+inter test rgb\n",
      "R@(1, 5, 10, 100, 1000)=[0.003481720964934096, 0.014175578214374533, 0.02561551852772942, 0.15443919423029098, 0.5884108430738623];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.003481720964934096, 0.014175578214374533, 0.02561551852772942, 0.15518527729420542, 0.589654314847053];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.002238249191743347, 0.007212136284506341, 0.014921661278288983, 0.0890325789604576, 0.44093509077343945];\n",
      "mIOU=0.0028;\n",
      "mRank=1540.61;\n",
      "intra+inter val flow\n",
      "R@(1, 5, 10, 100, 1000)=[0.004545454545454545, 0.01555023923444976, 0.03110047846889952, 0.16052631578947368, 0.6050239234449761];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.004545454545454545, 0.01555023923444976, 0.03110047846889952, 0.16052631578947368, 0.6062200956937799];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.004784688995215311, 0.00909090909090909, 0.016507177033492824, 0.09138755980861243, 0.43851674641148325];\n",
      "mIOU=0.0045;\n",
      "mRank=1597.16;\n",
      "intra+inter test flow\n",
      "R@(1, 5, 10, 100, 1000)=[0.004973887092762994, 0.01840338224322308, 0.030838099975130564, 0.16065655309624471, 0.586421288236757];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.004973887092762994, 0.01840338224322308, 0.030838099975130564, 0.16090524745088286, 0.5876647600099478];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.004476498383486694, 0.011937329022631187, 0.01840338224322308, 0.0920169112161154, 0.4297438448147227];\n",
      "mIOU=0.0046;\n",
      "mRank=1570.50;\n",
      "intra val rgb\n",
      "R@(1, 5, 10, 100, 1000)=[0.0004784688995215311, 0.0019138755980861245, 0.005741626794258373, 0.041626794258373206, 0.28875598086124404];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.0004784688995215311, 0.0019138755980861245, 0.005741626794258373, 0.041626794258373206, 0.28875598086124404];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.0004784688995215311, 0.0014354066985645933, 0.003110047846889952, 0.021770334928229666, 0.1660287081339713];\n",
      "mIOU=0.0005;\n",
      "mRank=3522.49;\n",
      "intra test rgb\n",
      "R@(1, 5, 10, 100, 1000)=[0.0004973887092762995, 0.0012434717731907485, 0.005471275802039294, 0.0450136781895051, 0.2685899030092017];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.0004973887092762995, 0.0012434717731907485, 0.005471275802039294, 0.0450136781895051, 0.2685899030092017];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.0004973887092762995, 0.0012434717731907485, 0.0029843322556577967, 0.021387714498880876, 0.1641382740611788];\n",
      "mIOU=0.0005;\n",
      "mRank=3438.87;\n",
      "intra val flow\n",
      "R@(1, 5, 10, 100, 1000)=[0.0011961722488038277, 0.005741626794258373, 0.010526315789473684, 0.06626794258373206, 0.365311004784689];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.0011961722488038277, 0.005741626794258373, 0.010526315789473684, 0.06626794258373206, 0.365311004784689];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.0009569377990430622, 0.0033492822966507177, 0.005263157894736842, 0.03588516746411483, 0.204066985645933];\n",
      "mIOU=0.0011;\n",
      "mRank=2764.76;\n",
      "intra test flow\n",
      "R@(1, 5, 10, 100, 1000)=[0.0012434717731907485, 0.005222581447401144, 0.010196468540164138, 0.05894056204924148, 0.3456851529470281];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.0012434717731907485, 0.005222581447401144, 0.010196468540164138, 0.05894056204924148, 0.3456851529470281];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.0012434717731907485, 0.003481720964934096, 0.005719970156677443, 0.03382243223078836, 0.20019895548371053];\n",
      "mIOU=0.0012;\n",
      "mRank=2734.43;\n",
      "inter val rgb\n",
      "R@(1, 5, 10, 100, 1000)=[0.00430622009569378, 0.01028708133971292, 0.019138755980861243, 0.09808612440191387, 0.43923444976076553];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.00430622009569378, 0.011244019138755982, 0.019617224880382776, 0.09952153110047847, 0.44186602870813396];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.0023923444976076554, 0.00645933014354067, 0.012200956937799042, 0.0784688995215311, 0.4093301435406699];\n",
      "mIOU=0.0034;\n",
      "mRank=3071.95;\n",
      "inter test rgb\n",
      "R@(1, 5, 10, 100, 1000)=[0.004973887092762994, 0.012434717731907486, 0.01865207659786123, 0.0945038547624969, 0.40313354886844066];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.004973887092762994, 0.012683412086545635, 0.019398159661775678, 0.09748818701815469, 0.4058691867694603];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.002486943546381497, 0.006963441929868192, 0.010693857249440438, 0.07659786122855011, 0.36831633921909973];\n",
      "mIOU=0.0039;\n",
      "mRank=2886.64;\n",
      "inter val flow\n",
      "R@(1, 5, 10, 100, 1000)=[0.004784688995215311, 0.013397129186602871, 0.020813397129186603, 0.09641148325358852, 0.4131578947368421];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.004784688995215311, 0.013397129186602871, 0.020813397129186603, 0.09784688995215311, 0.41770334928229663];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.0033492822966507177, 0.007655502392344498, 0.013157894736842105, 0.07177033492822966, 0.36411483253588517];\n",
      "mIOU=0.0039;\n",
      "mRank=3156.44;\n",
      "inter test flow\n",
      "R@(1, 5, 10, 100, 1000)=[0.004725192738124845, 0.012932106441183784, 0.019895548371051976, 0.09226560557075354, 0.40313354886844066];\n",
      "R@(1, 5, 10, 100, 1000),0.75=[0.004725192738124845, 0.013429495150460085, 0.020890325789604577, 0.09400646605322059, 0.40661526983337476];\n",
      "R@(1, 5, 10, 100, 1000),didemo=[0.003481720964934096, 0.0074608306391444916, 0.010942551604078588, 0.06789355881621487, 0.3501616513305148];\n",
      "mIOU=0.0042;\n",
      "mRank=2889.13;\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import h5py\n",
    "from evaluation import RetrievalEvaluation\n",
    "\n",
    "loss_set = ['', '_intra', '_inter']\n",
    "cue_set = ['rgb', 'flow']\n",
    "subset_set = ['val', 'test']\n",
    "\n",
    "time_breakdown = []\n",
    "\n",
    "def format_loss(x):\n",
    "    if '_' in x:\n",
    "        return x.replace('_', '')\n",
    "    elif len(x) == 0:\n",
    "        return 'intra+inter'\n",
    "    return x\n",
    "\n",
    "for loss, cue, subset in itertools.product(*[loss_set, cue_set, subset_set]):\n",
    "    corpus_file = f'data/interim/mcn{loss}/corpus_{subset}_{cue}.hdf5'\n",
    "    queries_file = f'data/interim/mcn{loss}/queries_{subset}_{cue}.hdf5'\n",
    "    annotations_file = f'data/raw/{subset}_data.json'\n",
    "    judge = RetrievalEvaluation(corpus_file, annotations_file, (1, 5, 10, 100, 1000))\n",
    "\n",
    "    with h5py.File(queries_file, 'r') as fid:\n",
    "        import time\n",
    "        start = time.time()\n",
    "        for sample_key, h5ds in fid.items():\n",
    "            query_id = int(sample_key)\n",
    "            query_vector = h5ds[:]\n",
    "            judge.eval_single_vector(query_vector, query_id)\n",
    "        time_breakdown.append([time.time() - start])\n",
    "    start = time.time()\n",
    "    performace = judge.eval()\n",
    "    time_breakdown[-1].append(time.time() - start)\n",
    "    loss = format_loss(loss)\n",
    "    print(f'{loss} {subset} {cue}')\n",
    "    print('R@{0:}={2:};\\nR@{0:},{1:}={3:};\\nR@{0:},didemo={4:};\\n'\n",
    "          'mIOU={5:.4f};\\nmRank={6:.2f};'\n",
    "          .format(judge.k, judge.iou_threshold,\n",
    "                  *performace))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Create GIF\n",
    "\n",
    "~~- Check tar file: only flow files~~\n",
    "\n",
    "1. Dump video list.\n",
    "\n",
    "    check notebook `1-inspect_videos.ipynb` section 1.2.d or 1.2.a-b\n",
    "    \n",
    "2. Make single GIF\n",
    "    libs := imageio\n",
    "    Run gif example\n",
    "\n",
    "    Take a look a `make_gif.py`\n",
    "\n",
    "    ~~TODO: Joblib for training~~\n",
    "    \n",
    "    _Note_: upload videos to youtube or S3 for AMT\n",
    "    \n",
    "## Task 6: Data for backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good.txt\n",
      "the camera zooms in and out on a group performing in front of people.\n",
      "the woman enter the building.\n",
      "fade in from black\n",
      "there is bush in the bottom left corner\n",
      "a brown haired boy puts his hand on his head.\n",
      "zoom in on bird\n",
      "man in multi colored hat enters frame\n",
      "the girl smiles near the baby.\n",
      "the cameraman reaches down and plays some keys on the piano.\n",
      "we see a bird skim the water ' fly away\n",
      "\n",
      "Bad.txt\n",
      "a young boy pushes pillows off himself.\n",
      "the cameraman wobbles the camera as he comes in closer.\n",
      "slack rope walker takes first step\n",
      "jet plane circles around to the left side for the first time\n",
      "we pass a orangish/yellowish marker during takeoff\n",
      "camera begins first pan to the right.\n",
      "both cats jump up onto the white bed\n",
      "camera first moves to the left just slightly\n",
      "baby in purple bib smiles as the camera zooms in\n",
      "a man in a black suit turns to a woman in a red suit.\n",
      "\n",
      "NMS.txt\n",
      "the dj is proud of the music he's playing.\n",
      "water is completely in view on beach\n",
      "both dogs get on a pillow located on the floor.\n",
      "a person near a lake.\n",
      "A man wearing a maroon colored vest is shown singing and raising his hands as he sings\n",
      "Eagle flying over the lake\n",
      "Two people playing horn instruments are walking in a parade\n",
      "group of people playing soccer\n",
      "a baby eats a spoon filled with food\n",
      "Man is playing drums and video pans to guy playing guitar.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "from corpus import Corpus\n",
    "from dataset import Queries\n",
    "\n",
    "val_rgb_corpus = 'data/interim/mcn/corpus_test_rgb.hdf5'\n",
    "val_flow_corpus = 'data/interim/mcn/corpus_test_flow.hdf5'\n",
    "val_rgb_queries = 'data/interim/mcn/queries_test_rgb.hdf5'\n",
    "val_flow_queries = 'data/interim/mcn/queries_test_flow.hdf5'\n",
    "val_annotations = 'data/raw/test_data.json'\n",
    "filename = 'test_results_rgb+flow.json'\n",
    "\n",
    "val_rgb_corpus = Corpus(val_rgb_corpus)\n",
    "val_flow_corpus = Corpus(val_flow_corpus, videos=val_rgb_corpus.videos)\n",
    "segments = list(map(tuple, val_rgb_corpus.segments.tolist()))\n",
    "val_gt_queries = Queries(\n",
    "    val_annotations, val_rgb_corpus.videos.tolist(), segments)\n",
    "TOPK = 20\n",
    "ALPHA = 0.5\n",
    "IOU_THRESHOLD = 1.0\n",
    "UNIQUE_VIDEOS_AT_K = 8\n",
    "# segments_ = val_rgb_corpus.segments * 5\n",
    "# segments_[:, 1] += 5\n",
    "# IOU_MATRIX = segments_iou(segments_, segments_)\n",
    "\n",
    "retrieval_results = {}\n",
    "segment_list = []\n",
    "# Collect samples to visualize\n",
    "good_samples = []\n",
    "bad_samples = []\n",
    "nms_samples = []\n",
    "\n",
    "num_unique_videos = []\n",
    "video_retrieved = []\n",
    "\n",
    "with h5py.File(val_rgb_queries, 'r') as frgb, h5py.File(val_flow_queries, 'r') as fflow:\n",
    "    for sample_key, h5ds in frgb.items():\n",
    "        query_id = int(sample_key)\n",
    "        query_rgb = h5ds[:]\n",
    "        query_flow = fflow[sample_key][:]\n",
    "        \n",
    "        rgb_distance = val_rgb_corpus.search(query_rgb)\n",
    "        flow_distance = val_flow_corpus.search(query_flow)\n",
    "        distance = ALPHA * rgb_distance + (1 - ALPHA) * flow_distance\n",
    "        # Manual indexing\n",
    "        distance_sorted_indices = np.argsort(distance)\n",
    "        distance_sorted = distance[distance_sorted_indices]\n",
    "        results = val_rgb_corpus.ind_to_repo(distance_sorted_indices)\n",
    "        results = results + (distance_sorted,)\n",
    "        # Keep topk (visualization purpose)\n",
    "        topk_video_indices = results[0][:TOPK]\n",
    "        topk_segment_indices = results[1][:TOPK]\n",
    "        topk_score = results[2][:TOPK]\n",
    "        # ground truth information\n",
    "        query = val_gt_queries[query_id]['description']\n",
    "        gt_video_index = val_gt_queries[query_id]['video_index']\n",
    "        gt_segment_indices = val_gt_queries[query_id]['segment_indices']\n",
    "        # Label predictions as TP/FP\n",
    "        tp_fp_videos = topk_video_indices == gt_video_index\n",
    "        tp_fp_segments = np.in1d(topk_segment_indices, gt_segment_indices)\n",
    "        tp_fp_labels = np.logical_and(tp_fp_videos, tp_fp_segments)\n",
    "        # Flexible criteria for TP\n",
    "        # i, j = np.meshgrid(gt_segment_indices, topk_segment_indices)\n",
    "        # topk_iou = np.max(tp_fp_videos[:, None] * IOU_MATRIX[i, j],\n",
    "        #                   axis=1)\n",
    "        # tp_fp_labels_soft = topk_iou >= IOU_THRESHOLD\n",
    "        # cum_tp_fp_labels = tp_fp_labels_soft.cumsum()\n",
    "        # Categorize results\n",
    "        if np.all(tp_fp_labels) == False:\n",
    "            bad_samples.append(query_id)\n",
    "        if np.any(tp_fp_labels) == True:\n",
    "            good_samples.append(query_id)\n",
    "        unique_videos = np.unique(topk_video_indices)\n",
    "        if len(unique_videos) < UNIQUE_VIDEOS_AT_K:\n",
    "            nms_samples.append(query_id)\n",
    "            \n",
    "        num_unique_videos.append(len(unique_videos))\n",
    "        video_retrieved.append(np.any(tp_fp_videos))\n",
    "        \n",
    "        retrieval_results[query_id] = {\n",
    "            'query': query,\n",
    "            'topk_video_indices': topk_video_indices.tolist(),\n",
    "            'topk_segment_indices': topk_segment_indices.tolist(),\n",
    "            'topk_scores': topk_score.tolist(),\n",
    "            'groundtruth_video_index': gt_video_index,\n",
    "            'groundtruth_segment_indices': gt_segment_indices.tolist(),\n",
    "            'tp_fp_labels': tp_fp_labels.tolist(),\n",
    "            # info about query\n",
    "            'retrieved_at_k': bool(np.any(tp_fp_labels)),\n",
    "            'num_unique_videos': len(unique_videos),\n",
    "            'is_video_retrieved': bool(np.any(tp_fp_videos)),\n",
    "        }\n",
    "video_list = val_rgb_corpus.videos.tolist()\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump({'results': retrieval_results,\n",
    "               'videos': video_list,\n",
    "               'segments': segments},\n",
    "              f)\n",
    "\n",
    "# Dump samples to check\n",
    "import random\n",
    "for subset, queries in [('Good.txt', good_samples),\n",
    "                        ('Bad.txt', bad_samples),\n",
    "                        ('NMS.txt', nms_samples)]:\n",
    "    with open(subset, 'w') as f:\n",
    "        for i in queries:\n",
    "            f.write('{}\\n'.format(i))\n",
    "    print(subset)\n",
    "    random.shuffle(queries)\n",
    "    for i in queries[:10]:\n",
    "        print(val_gt_queries[i]['description'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pctg video retrieved', sum(video_retrieved) / len(video_retrieved))\n",
    "print('Median number of unique videos', np.median(num_unique_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.bincount(num_unique_videos)\n",
    "plt.bar(range(1, 11), y[1:] / len(num_unique_videos))\n",
    "plt.ylabel('Pctg')\n",
    "_ = plt.xlabel('Number of uniques videos at k=10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalizing metrics\n",
    "\n",
    "## draft\n",
    "\n",
    "$\\text{HIT}(p_i^j) = \\underset{k}{\\max} ( \\text{tIOU}(p_i^j, a_k^l) \\ge \\delta)$\n",
    "\n",
    "- The prediction $p_i^j$ refers to $i\\text{-th}$ moment found in video $j$.\n",
    "\n",
    "- The $\\text{HIT}(p_i^j)$ is a binary variable.\n",
    "\n",
    "- $\\text{HIT}$ is True iff:\n",
    "    - There is an annotation $a_k^j$ in the video $j$, i.e. $j=l$.\n",
    "        - TODO: missing concept of query\n",
    "\n",
    "    - The overlap between the prediction $c_i$ and an annotation $a_k$ is greater or equal than $\\delta$.\n",
    "    \n",
    "    - We apply a consensus function such as $\\max$ to deal with multiple annotations.\n",
    "        \n",
    "I didn't like the sub-index in the $p$. I don't think that it's necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we only care about the top-1 prediction for a single query.\n",
    "\n",
    "$\\text{HIT}(p^j) = \\underset{k}{\\max} ( \\text{tIOU}(p^j, a_k^l) \\ge \\delta)$\n",
    "\n",
    "- The prediction $p^j$ refers to $i\\text{-th}$ moment found in video $j$.\n",
    "\n",
    "- $\\text{HIT}(p^j)$ is a binary variable. True means that we are able to retrieve the query from the corpus.\n",
    "\n",
    "- $\\text{HIT}$ is True iff:\n",
    "    - There is an annotation $a_k^j$ in the video $j$, i.e. $j=l$.\n",
    "\n",
    "    - The overlap between the prediction $c_i$ and an annotation $a_k$ is greater or equal than $\\delta$.\n",
    "    \n",
    "    - The $\\max$ function is a form of consensus that allows to deal with multiple annotations.\n",
    "    \n",
    "    - Opinion: $\\max$ might achieve the same purpose than using lower values of $\\delta$ with a single annotation.\n",
    "    \n",
    "        - TODO: check IOU between annotations per query.\n",
    "    \n",
    "In general,\n",
    "\n",
    "$\\text{HIT}(p^j) = f_{\\mathcal{A}} ( \\text{tIOU}(p^j, a_k^l) \\ge \\delta)$\n",
    "\n",
    "- How to define $f_{\\mathcal{A}}$? Is it out of the scope of the project?\n",
    "\n",
    "## Measuring weak agreement\n",
    "\n",
    "- 1st criterion: Annotations match either start or end.\n",
    "\n",
    "    Comment: I found this is True.\n",
    "\n",
    "- 2nd criterion: I fstart/end does not match, they are off at most by 1.\n",
    "\n",
    "    - This is criterios is not always valid. However, it applies for 96% of the queries.\n",
    "    \n",
    "    - When it does not apply, it is feasible to do majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: train\n",
      "Number of annomalies: 864\n",
      "Pctg of annomalies: 0.026177851840630206\n",
      "Alternatives if anomaly: [2]\n",
      "Pctg majority if anomaly: 1.0\n",
      "\n",
      "Subset: val\n",
      "Number of annomalies: 98\n",
      "Pctg of annomalies: 0.023444976076555026\n",
      "Alternatives if anomaly: [2]\n",
      "Pctg majority if anomaly: 1.0\n",
      "\n",
      "Subset: test\n",
      "Number of annomalies: 105\n",
      "Pctg of annomalies: 0.02611290723700572\n",
      "Alternatives if anomaly: [2]\n",
      "Pctg majority if anomaly: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "VALID_OFFSETS = [-1, 1]\n",
    "MIN_TIME, MAX_TIME = 0, 5\n",
    "\n",
    "filename = 'data/raw/{}_data.json'\n",
    "no_weak_agreement = {}\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    with open(filename.format(subset), 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    no_weak_agreement[subset] = {'offset': [],\n",
    "                                 'alternatives': [],\n",
    "                                 'majority': []}\n",
    "    nwa_by_offset = no_weak_agreement[subset]['offset']\n",
    "    nwa_alternatives = no_weak_agreement[subset]['alternatives']\n",
    "    nwa_majority = no_weak_agreement[subset]['majority']\n",
    "    print('Subset:', subset)\n",
    "    for query in data:\n",
    "        annotations = np.array(query['times'])\n",
    "        start, end = np.split(annotations, 2, axis=1)\n",
    "        start_matched_other = np.equal(start, start[:, None]).sum(axis=1) > 1\n",
    "        end_matched_other = np.equal(end, end[:, None]).sum(axis=1) > 1\n",
    "        start_or_end_matched_other = np.logical_or(start_matched_other,\n",
    "                                                   end_matched_other)\n",
    "        assert start_or_end_matched_other.any()\n",
    "        # if all are equal, no purpose of testing offset\n",
    "        unique_intervals, counts = np.unique(annotations, axis=0, return_counts=True)\n",
    "        if unique_intervals.shape[0] == 1:\n",
    "            continue\n",
    "\n",
    "        start_off_match = np.zeros(start.shape, dtype=bool)\n",
    "        end_off_match = np.zeros(end.shape, dtype=bool)\n",
    "        for offset in VALID_OFFSETS:\n",
    "            start_off = np.minimum(np.maximum(start + offset, MIN_TIME), MAX_TIME)\n",
    "            start_off_matched_other = np.equal(start_off, start[:, None]).sum(axis=1) >= 1\n",
    "            start_off_match = np.logical_or(\n",
    "                start_off_matched_other, start_off_match)\n",
    "\n",
    "            end_off = np.minimum(np.maximum(end + offset, MIN_TIME), MAX_TIME)\n",
    "            end_off_matched_other = np.equal(end_off, end[:, None]).sum(axis=1) >= 1\n",
    "            end_off_match = np.logical_or(\n",
    "                end_off_matched_other, end_off_match)\n",
    "        start_or_end_off_matched_other = np.logical_or(start_off_match,\n",
    "                                                       end_off_match)\n",
    "        if not start_or_end_off_matched_other.any():\n",
    "            nwa_by_offset.append(query['annotation_id'])\n",
    "            nwa_alternatives.append(len(unique_intervals))\n",
    "            nwa_majority.append(counts.max() / counts.sum() > 0.5)\n",
    "    print('Number of annomalies:', len(nwa_by_offset))\n",
    "    print('Pctg of annomalies:', len(nwa_by_offset) / len(data))\n",
    "    print('Alternatives if anomaly:', np.unique(nwa_alternatives))\n",
    "    print('Pctg majority if anomaly:', sum(nwa_majority) / len(nwa_majority))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- Make table with MCN results (1 hour)\n",
    "\n",
    "- Beyond metric preformance:\n",
    "\n",
    "    - retrieved or not at K (add column to enable for sorting)\n",
    "    \n",
    "    - retrieved video at k\n",
    "    \n",
    "        - compute number\n",
    "        \n",
    "    - number of unique videos at k\n",
    "    \n",
    "    - max number of segments per video, retrieved at k."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
