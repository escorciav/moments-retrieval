{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Towards feature engineering\n",
    "\n",
    "## 1.1 Take a look at public metadata\n",
    "\n",
    "### 1.1.a Grab videos from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_annotations(subset='train'):\n",
    "    with open(f'../data/raw/{subset}_data.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def read_hash(filename='/home/escorciav/datasets/didemo/annotations/yfcc100m_hash.txt'):\n",
    "    \"Parse text-file with hash\"\n",
    "    lines = open(filename).readlines()\n",
    "    yfcc100m_hash = {}\n",
    "    for line_count, line in enumerate(lines):\n",
    "        line = line.strip().split('\\t')\n",
    "        yfcc100m_hash[line[0]] = line[1]\n",
    "    return yfcc100m_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_annotations('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there missing videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "video_dir = Path('/home/escorciav/datasets/didemo/videos')\n",
    "video_dir = Path('/home/escorciav/Downloads/didemo/missing_videos/')\n",
    "\n",
    "num_videos = 0\n",
    "for i in data:\n",
    "#     print(i.keys())\n",
    "#     print(i['video'])\n",
    "    video_file = video_dir / (i['video'] + '.mp4')\n",
    "    if video_file.is_file():\n",
    "        num_videos += 1\n",
    "    else:\n",
    "        video_file = \n",
    "        \n",
    "print(f'[{num_videos}/{len(data)}] {len(data)-num_videos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.b Check additional videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "extra_a = Path('/home/escorciav/Downloads/didemo/missing_videos/')\n",
    "extra_b = Path('/home/escorciav/Downloads/didemo/missing_videos_AWS/')\n",
    "repeated, indeed = 0, 0\n",
    "for i in extra_b.iterdir():\n",
    "    j = extra_a / i.name\n",
    "    if j.is_file():\n",
    "        repeated += 1\n",
    "        cmd = ['diff', i, j]\n",
    "        output = subprocess.run(cmd, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "        if output.returncode == 0:\n",
    "            indeed += 1\n",
    "print(f'Potential repeteated files: {repeated}. Confirmed {indeed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set with all videos of this dataset\n",
    "\n",
    "We will duplicate '.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folders = [\n",
    "    Path('/home/escorciav/datasets/didemo/missing/missing_videos/'),\n",
    "    Path('/home/escorciav/datasets/didemo/missing/missing_videos_AWS/'),\n",
    "    Path('/home/escorciav/datasets/didemo/videos/')\n",
    "]\n",
    "\n",
    "videos = set()\n",
    "for i in folders:\n",
    "    for j in i.iterdir():\n",
    "        videos.add(j.name)\n",
    "        if j.suffix == '.mp4':\n",
    "            videos.add(j.stem)\n",
    "\n",
    "num_missing = []\n",
    "for i in ['train', 'val', 'test']:\n",
    "    num_missing.append(0)\n",
    "    for j in read_annotations(i):\n",
    "        if j['video'] not in videos:\n",
    "            num_missing[-1] += 1\n",
    "            print(j['video'])\n",
    "print(f'Number clips missing [{sum(num_missing)}-'\n",
    "      f'{num_missing[0]}/{num_missing[1]}/{num_missing[2]}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workaround for videos that where not in AWS or Lisas's website.\n",
    "\n",
    "I turned out that I only needed two videos, thus I didn't automate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "missing_videos = [\n",
    "    '33234611@N00_3567949618_0bee41c6f7.mp4',\n",
    "    '15389242@N00_4268126780_be074c803c.mov',\n",
    "    '15389242@N00_4268126780_be074c803c.mov',\n",
    "    '33234611@N00_3567949618_0bee41c6f7.mp4',\n",
    "    '15389242@N00_4268126780_be074c803c.mov',\n",
    "    '15389242@N00_4268126780_be074c803c.mov',\n",
    "    '15389242@N00_4268126780_be074c803c.mov',\n",
    "]\n",
    "missing_videos = set(missing_videos)\n",
    "\n",
    "def get_aws_link(h):\n",
    "    return f'https://multimedia-commons.s3-us-west-2.amazonaws.com/data/videos/mp4/{h[:3]}/{h[3:6]}/{h}.mp4'\n",
    "\n",
    "PATH = Path('/home/escorciav/datasets/didemo/missing/missing_trial/')\n",
    "VIDEO_DIR = Path('/home/escorciav/datasets/didemo/videos/')\n",
    "\n",
    "id2hash = read_hash()\n",
    "for video_name in missing_videos:\n",
    "    video_id = video_name.split('_')[1]\n",
    "    video_hash = id2hash[video_id]\n",
    "\n",
    "    filename_hash = PATH / (video_hash + '.mp4')\n",
    "    if filename_hash.is_file():\n",
    "        target = VIDEO_DIR / (video_name + '.mp4')\n",
    "        filename_hash.rename(target)\n",
    "    else:\n",
    "        print('Manual download, sorry :p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge missing videos into big folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "main_folder = [\n",
    "    Path('/home/escorciav/datasets/didemo/videos/')\n",
    "]\n",
    "\n",
    "extra_folders = [\n",
    "    Path('/home/escorciav/datasets/didemo/missing/missing_videos_AWS/'),\n",
    "    Path('/home/escorciav/datasets/didemo/missing/missing_videos/'),\n",
    "]\n",
    "\n",
    "videos = set()\n",
    "for i in main_folder:\n",
    "    for j in i.iterdir():\n",
    "        videos.add(j.name)\n",
    "        if j.suffix == '.mp4':\n",
    "            videos.add(j.stem)\n",
    "\n",
    "num_missing = []\n",
    "missing_set = set()\n",
    "for i in ['train', 'val', 'test']:\n",
    "    num_missing.append(0)\n",
    "    for j in read_annotations(i):\n",
    "        if j['video'] not in videos:\n",
    "            num_missing[-1] += 1\n",
    "            missing_set.add(j['video'])\n",
    "print(f'Number clips missing [{sum(num_missing)}-'\n",
    "      f'{num_missing[0]}/{num_missing[1]}/{num_missing[2]}]')\n",
    "\n",
    "print('Moving data from extra folders to main_folders')\n",
    "assert len(main_folder) == 1\n",
    "main_folder = main_folder[0]\n",
    "for i in missing_set:\n",
    "    for j in extra_folders:\n",
    "        full_i = (j / i)\n",
    "        if full_i.is_file():\n",
    "            target = main_folder / (i + '.mp4')\n",
    "            full_i.rename(target)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Getting metadata from videos\n",
    "\n",
    "### 1.2.a Export video names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "videos_file = '../data/raw/videos.csv'\n",
    "video_lists = []\n",
    "with open(videos_file, 'w') as fw:\n",
    "    fw.write('video_id,subset\\n')\n",
    "    for subset in ['train', 'val', 'test']:\n",
    "        dataset_filename = '../data/raw/{}_data.json'.format(subset)\n",
    "\n",
    "        with open(dataset_filename) as fr:\n",
    "            dataset = json.load(fr)\n",
    "    \n",
    "        video_lists.append(set())\n",
    "        for i in dataset:\n",
    "            video_lists[-1].add(i['video'])\n",
    "            # sanity check videos to make sure videos are not mixed\n",
    "            if len(video_lists) > 1:\n",
    "                assert all([i['video'] not in j for j in video_lists[0:-1]])\n",
    "    \n",
    "        for i in video_lists[-1]:\n",
    "            fw.write(f'{i},{subset}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check videos and update CSV-file accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "filename = '../data/raw/videos.csv'\n",
    "dirname = Path('/home/escorciav/datasets/didemo/videos/')\n",
    "df = pd.read_csv(filename)\n",
    "for i, row in df.iterrows():\n",
    "    filename = dirname / (row['video_id'] + '.mp4')\n",
    "    if not filename.exists():\n",
    "        assert False\n",
    "    df.loc[i, 'video_id'] = row['video_id'] + '.mp4'\n",
    "df.to_csv('../data/raw/cev.csv', index=False)\n",
    "# I had to do this because I was sleeping and somthing was working well in that monda\n",
    "!mv ../data/raw/cev.csv ../data/raw/videos.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.b Export metadata with video-utils\n",
    "\n",
    "```\n",
    "python tools/video_info.py \\\n",
    "  -i ~/projects/moments-retrieval/data/raw/videos.txt \\\n",
    "  -o ~/projects/moments-retrieval/data/raw/videos_info.csv \\\n",
    "  -r ~/datasets/didemo/videos/ \\\n",
    "  -n 48 --verbose 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.c Merge CSV files\n",
    "\n",
    "checking corrupted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/raw/videos_info.csv')\n",
    "corrupted = np.zeros(len(df), dtype=bool)\n",
    "for i in ['duration', 'frame_rate', 'num_frames', 'width', 'height']:\n",
    "    corrupted = np.logical_or(corrupted, pd.isna(df[i]))\n",
    "print(f'Num corrupted [{corrupted.sum()}/{len(corrupted)}]')\n",
    "print(df.loc[corrupted, 'video_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: merge CSV\n",
    "\n",
    "[check this](https://stackoverflow.com/questions/39862654/pandas-concat-of-multiple-data-frames-using-only-common-columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/raw/videos_info.csv')\n",
    "print(\n",
    "    'Duration [max, min, mean]: ['\n",
    "    f'{df.loc[:, \"duration\"].max()}, '\n",
    "    f'{df.loc[:, \"duration\"].min()}, '\n",
    "    f'{df.loc[:, \"duration\"].mean()}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_durations = df.loc[:, 'duration'].dropna()\n",
    "duration_edges = [-1, 0 + 1e-3] + list(range(5, 40, 5)) + [df.loc[:, \"duration\"].max()]\n",
    "videos_per_duration, _ = np.histogram(video_durations, bins=duration_edges)\n",
    "assert len(video_durations) == videos_per_duration.sum()\n",
    "for i, v in enumerate(videos_per_duration):\n",
    "    print(f'[{duration_edges[i]},{duration_edges[i+1]}] = {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.d Check dumping frames\n",
    "\n",
    "1. Generate files for dumping frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = 'data/raw/train_data.json'\n",
    "file_list = 'data/raw/videos_train.txt'\n",
    "videos = set()\n",
    "with open(filename) as f:\n",
    "    data = json.load(f)\n",
    "    for i in data:\n",
    "        videos.add(i['video'])\n",
    "\n",
    "with open(file_list, 'w') as fw:\n",
    "    for i in videos:\n",
    "        fw.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Adobe. This is a replica of content from [1.2.a-b (this notebook)]()\n",
    "\n",
    "1. Install video-utils\n",
    "\n",
    "    ```bash\n",
    "    git clone https://github.com/escorciav/video-utils\n",
    "    conda create -y -n video-utils python=3.6 pandas joblib && conda activate video-utils && conda install -y ffmpeg -c conda-forge\n",
    "    ```\n",
    "\n",
    "    Note: I added a hot-fix because video name contains special characters.\n",
    "\n",
    "    apply this diff to this commit `TODO`\n",
    "\n",
    "    ```\n",
    "    TODO\n",
    "    ```\n",
    "\n",
    "2. Extract frames\n",
    "\n",
    "    rescale to 320x240 and frame-rate 5FPS\n",
    "\n",
    "    ```bash\n",
    "    conda activate video-utils\n",
    "    python tools/batch_dump_frames.py -i [input-list] -o [output-dir] -s [csv-report] --filters \"-vf fps=5 scale=320:240 -qscale:v 2\" -r [root] -n 32\n",
    "    ```\n",
    "\n",
    "    _troubleshooting_\n",
    "\n",
    "    running code\n",
    "\n",
    "    ```\n",
    "    ModuleNotFoundError: No module named 'okvideo'                                                                                              \n",
    "                                                                                                                                                  Uncaught exception. Entering post mortem debugging                                                                                                                                                                                                                               Running 'cont' or 'step' will restart the program                                                                                           \n",
    "    > []/video-utils/tools/batch_dump_frames.py(10)<module>()                                                        \n",
    "    -> from okvideo.ffmpeg import dump_frames\n",
    "    ```\n",
    "\n",
    "    fix: `export PYTHONPATH=$PWD` if it's executed from project dir.\n",
    "\n",
    "1. Verify if the frames were dumped succesfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l data/raw/videos_val.txt\n",
    "!wc -l data/raw/videos_test.txt\n",
    "!wc -l data/raw/videos_train.txt\n",
    "!ls /mnt/ssd/tmp/didemo/frames/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1094+1037+8511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "filename = '../data/raw/videos_train.txt'\n",
    "dirname = '/mnt/ssd/tmp/didemo/frames/'\n",
    "logfile = '../data/interim/log/train-frames-01.csv'\n",
    "missing = 0\n",
    "with open(filename) as f:\n",
    "    for i in f:\n",
    "        video_name = os.path.splitext(i.strip())[0]\n",
    "        video_dir = os.path.join(dirname, video_name)\n",
    "        if not os.path.isdir(video_dir):\n",
    "            missing += 1\n",
    "            continue\n",
    "        if len(os.listdir(video_dir)) == 0:\n",
    "            missing += 1\n",
    "    print('Num videos without frames:', missing)\n",
    "df = pd.read_csv(logfile, header=None)\n",
    "missing_log = (df.loc[:, 1] == False).sum()\n",
    "print('Num videos without frames:', missing_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Tar frames\n",
    "\n",
    "Try to follow this name convention `_resolution_[fps].tar`\n",
    "\n",
    "`tar -cf frames_320x240_5fps.tar frames/`\n",
    "\n",
    "- Check size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -chs /mnt/ssd/tmp/didemo/frames/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
