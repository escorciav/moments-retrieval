{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New split Charades-STA\n",
    "Charades does not have a proper validation split to tune HPS on. <br>\n",
    "In this script we fuse train and test and derive, by random split, train_dev and val_dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import subprocess\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['videos', 'moments', 'date', 'git_hash', 'responsible'])\n",
      "6913c98bc58ef1d3449bf3dca249069c0496236b\n",
      "EscorciaSSGR\n",
      "2019-01-21T02:00:48.670279\n"
     ]
    }
   ],
   "source": [
    "#Load current splits:\n",
    "train = json.load(open('../data/processed/charades-sta/train-01.json','r'))\n",
    "test  = json.load(open('../data/processed/charades-sta/test-01.json','r'))\n",
    "print(train.keys())\n",
    "print(train['git_hash'])\n",
    "print(train['responsible'])\n",
    "print(train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create common info\n",
    "date = str(datetime.now())\n",
    "git_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'],universal_newlines=True).strip()\n",
    "responsible = 'Mattia Soldan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary\n",
    "train_dev = {'date':date, 'git_hash':git_hash, 'responsible':responsible}\n",
    "val_dev   = {'date':date, 'git_hash':git_hash, 'responsible':responsible}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge videos:\n",
    "all_videos_id    = set(list(train['videos'].keys())+list(test['videos'].keys()))\n",
    "train_dev_perc   = 0.80\n",
    "train_dev_videos = random.sample(all_videos_id, int(train_dev_perc * len(all_videos_id)))\n",
    "val_dev_videos   = all_videos_id.difference(set(train_dev_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in train (original split) 5336\n",
      "Number of videos in test (original split) 1334\n",
      "Number of moments in train (original split) 12404\n",
      "Number of moments in test (original split) 3720\n",
      "Num overlapping video in training: 4254\n",
      "Num overlapping video in testing: 252\n",
      "Overlapping % video train 79.72\n",
      "Overlapping % video test 18.89\n"
     ]
    }
   ],
   "source": [
    "# Analize overlapping with previous splits:\n",
    "l_v_tr = len(train['videos'].keys())\n",
    "l_v_te = len(test['videos'].keys())\n",
    "print(f'Number of videos in train (original split) {l_v_tr}')\n",
    "print(f'Number of videos in test (original split) {l_v_te}')\n",
    "\n",
    "l_m_tr = len(train['moments'])\n",
    "l_m_te = len(test['moments'])\n",
    "print(f'Number of moments in train (original split) {l_m_tr}')\n",
    "print(f'Number of moments in test (original split) {l_m_te}')\n",
    "\n",
    "inter_tr = set(train_dev_videos).intersection(set(train['videos'].keys()))\n",
    "inter_te = set(val_dev_videos).intersection(set(test['videos'].keys()))\n",
    "print(f'Num overlapping video in training: {len(inter_tr)}')\n",
    "print(f'Num overlapping video in testing: {len(inter_te)}')\n",
    "\n",
    "print(f'Overlapping % video train {len(inter_tr)/l_v_tr *100:.2f}')\n",
    "print(f'Overlapping % video test {len(inter_te)/l_v_te*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split videos according to these video ids\n",
    "tot_videos = train['videos']\n",
    "tot_videos.update(test['videos'])\n",
    "train_dev['videos'] = {k:v for k,v in tot_videos.items() if k in train_dev_videos}\n",
    "val_dev['videos']   = {k:v for k,v in tot_videos.items() if k in val_dev_videos}\n",
    "# Split moments\n",
    "tot_moments = train['moments'] + test['moments']\n",
    "train_dev['moments'] = [m for m in tot_moments if m['video'] in train_dev_videos]\n",
    "val_dev['moments']   = [m for m in tot_moments if m['video'] in val_dev_videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in train (original split) 5336\n",
      "Number of videos in test (original split) 1334\n",
      "Number of moments in train (original split) 12901\n",
      "Number of moments in test (original split) 3223\n"
     ]
    }
   ],
   "source": [
    "# Analize new splits:\n",
    "l_v_tr = len(train_dev['videos'].keys())\n",
    "l_v_va = len(val_dev['videos'].keys())\n",
    "print(f'Number of videos in train (original split) {l_v_tr}')\n",
    "print(f'Number of videos in test (original split) {l_v_va}')\n",
    "\n",
    "l_m_tr = len(train_dev['moments'])\n",
    "l_m_va = len(val_dev['moments'])\n",
    "print(f'Number of moments in train (original split) {l_m_tr}')\n",
    "print(f'Number of moments in test (original split) {l_m_va}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump data\n",
    "json.dump(train_dev, open('../data/processed/charades-sta/train-dev.json','w'))\n",
    "json.dump(val_dev,   open('../data/processed/charades-sta/val-dev.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import subprocess\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['videos', 'moments', 'date', 'git_hash', 'responsible'])\n",
      "6913c98bc58ef1d3449bf3dca249069c0496236b\n",
      "EscorciaSSGR\n",
      "2019-01-21T02:00:48.670279\n"
     ]
    }
   ],
   "source": [
    "#Load current splits:\n",
    "train = json.load(open('../data/processed/charades-sta/train-01.json','r'))\n",
    "print(train.keys())\n",
    "print(train['git_hash'])\n",
    "print(train['responsible'])\n",
    "print(train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create common info\n",
    "date = str(datetime.now())\n",
    "git_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'],universal_newlines=True).strip()\n",
    "responsible = 'Mattia Soldan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary\n",
    "train_dev2 = {'date':date, 'git_hash':git_hash, 'responsible':responsible}\n",
    "val_dev2   = {'date':date, 'git_hash':git_hash, 'responsible':responsible}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge videos:\n",
    "all_videos_id    = set(list(train['videos'].keys()))\n",
    "train_dev_perc   = 0.80\n",
    "train_dev_videos = random.sample(all_videos_id, int(train_dev_perc * len(all_videos_id)))\n",
    "val_dev_videos   = all_videos_id.difference(set(train_dev_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split videos according to these video ids\n",
    "tot_videos = train['videos']\n",
    "train_dev2['videos'] = {k:v for k,v in tot_videos.items() if k in train_dev_videos}\n",
    "val_dev2['videos']   = {k:v for k,v in tot_videos.items() if k in val_dev_videos}\n",
    "# Split moments\n",
    "tot_moments = train['moments'] \n",
    "train_dev2['moments'] = [m for m in tot_moments if m['video'] in train_dev_videos]\n",
    "val_dev2['moments']   = [m for m in tot_moments if m['video'] in val_dev_videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in train (original split) 5336\n",
      "Number of videos in train_dev2 4268\n",
      "Number of videos in val_dev2 1068\n",
      "Number of moments in train (original) 12404\n",
      "Number of moments in train 9894\n",
      "Number of moments in test 2510\n"
     ]
    }
   ],
   "source": [
    "# Analize new splits:\n",
    "n = len(train['videos'].keys())\n",
    "print(f'Number of videos in train (original split) {n}')\n",
    "n = len(train_dev2['videos'].keys())\n",
    "print(f'Number of videos in train_dev2 {n}')\n",
    "n = len(val_dev2['videos'].keys())\n",
    "print(f'Number of videos in val_dev2 {n}')\n",
    "\n",
    "n = len(train['moments'])\n",
    "print(f'Number of moments in train (original) {n}')\n",
    "n = len(train_dev2['moments'])\n",
    "print(f'Number of moments in train {n}')\n",
    "n = len(val_dev2['moments'])\n",
    "print(f'Number of moments in test {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump data\n",
    "json.dump(train_dev2, open('../data/processed/charades-sta/train-dev2.json','w'))\n",
    "json.dump(val_dev2,   open('../data/processed/charades-sta/val-dev2.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
