{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Preparing inputs for [video-utils](https://git.corp.adobe.com/escorcia/video-utils) tools\n",
    "\n",
    "- Create file with all the video names\n",
    "\n",
    "- Divide and conquer strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!split -d -n l/10 data/raw/all_videos.txt data/raw/videos-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Double check commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1068 data/raw/videos-00\n",
      "  1063 data/raw/videos-01\n",
      "  1065 data/raw/videos-02\n",
      "  1064 data/raw/videos-03\n",
      "  1064 data/raw/videos-04\n",
      "  1065 data/raw/videos-05\n",
      "  1064 data/raw/videos-06\n",
      "  1063 data/raw/videos-07\n",
      "  1063 data/raw/videos-08\n",
      "  1063 data/raw/videos-09\n",
      " 10642 total\n"
     ]
    }
   ],
   "source": [
    "# !head -n 1 data/raw/videos-0*\n",
    "!wc -l data/raw/videos-0*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Double check that `adobe/extract_frames.[sh/condor]` are pointitng to the appropriate folders\n",
    "\n",
    "3) Launch job `condor_submit adobe/extract_frames.condor`\n",
    "\n",
    "4) Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed jobs [10/10]\n",
      "==> data/interim/didemo/frame_extraction/0_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1068 out of 1068 | elapsed: 27.6min finished\n",
      "2018-07-12 07:37:05,155 INFO     [batch_dump_frames.py:53]: Creating summary file...\n",
      "\n",
      "==> data/interim/didemo/frame_extraction/1_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1063 out of 1063 | elapsed: 27.4min finished\n",
      "2018-07-12 07:36:48,806 INFO     [batch_dump_frames.py:53]: Creating summary file...\n",
      "\n",
      "==> data/interim/didemo/frame_extraction/2_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1065 out of 1065 | elapsed: 29.9min finished\n",
      "2018-07-12 07:40:33,894 INFO     [batch_dump_frames.py:53]: Creating summary file...\n",
      "\n",
      "==> data/interim/didemo/frame_extraction/3_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1064 out of 1064 | elapsed: 60.4min finished\n",
      "2018-07-12 08:09:55,599 INFO     [batch_dump_frames.py:53]: Creating summary file...\n",
      "\n",
      "==> data/interim/didemo/frame_extraction/4_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1064 out of 1064 | elapsed: 60.4min finished\n",
      "2018-07-12 08:09:55,582 INFO     [batch_dump_frames.py:53]: Creating summary file...\n",
      "\n",
      "==> data/interim/didemo/frame_extraction/5_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1065 out of 1065 | elapsed: 63.6min finished\n",
      "2018-07-12 08:13:46,294 INFO     [batch_dump_frames.py:53]: Creating summary file...\n",
      "\n",
      "==> data/interim/didemo/frame_extraction/6_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1064 out of 1064 | elapsed: 63.5min finished\n",
      "2018-07-12 08:13:40,796 INFO     [batch_dump_frames.py:53]: Creating summary file...\n",
      "\n",
      "==> data/interim/didemo/frame_extraction/7_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1063 out of 1063 | elapsed: 63.6min finished\n",
      "2018-07-12 08:13:45,705 INFO     [batch_dump_frames.py:53]: Creating summary file...\n",
      "\n",
      "==> data/interim/didemo/frame_extraction/8_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1063 out of 1063 | elapsed: 26.3min finished\n",
      "2018-07-12 07:35:52,155 INFO     [batch_dump_frames.py:53]: Creating summary file...\n",
      "\n",
      "==> data/interim/didemo/frame_extraction/9_300h.log <==\n",
      "[Parallel(n_jobs=-1)]: Done 1063 out of 1063 | elapsed: 42.7min finished\n",
      "2018-07-12 07:53:11,308 INFO     [batch_dump_frames.py:53]: Creating summary file...\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "dirname = 'data/interim/didemo/frame_extraction/'\n",
    "log_wildcard = os.path.join(dirname, '*_300h.log')\n",
    "csv_wildcard = os.path.join(dirname, '*_300h.csv')\n",
    "num_jobs = len(list(glob.glob(log_wildcard)))\n",
    "num_summary_files = len(list(glob.glob(csv_wildcard)))\n",
    "print(f'Completed jobs [{num_summary_files}/{num_jobs}]')\n",
    "!tail -n 2 $log_wildcard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting DiDeMo frames at 5FPS and 320x240 took roughly an hour on ten machines with multiple cores\n",
    "\n",
    "5) Check if all videos were extracted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of buggy videos 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: 0, dtype: object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "dirname = 'data/interim/didemo/frame_extraction/'\n",
    "csv_wildcard = os.path.join(dirname, '*_300h.csv')\n",
    "df = []\n",
    "for i in glob.glob(csv_wildcard):\n",
    "    df.append(pd.read_csv(i, header=None))\n",
    "df = pd.concat(df, axis=0, ignore_index=True)\n",
    "print('Number of buggy videos', (df.loc[:, 1] == False).sum())\n",
    "df.loc[df[1] == False, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Apparently the video appears twice in the dataset with different extension. We double check that the video correspond to the same content, thus we ignore this error.\n",
    "\n",
    "6) Merge all tar-files:\n",
    "\n",
    "I used the file `adobe/merge_frames.sh` which should do somth close to this:\n",
    "\n",
    "```bash\n",
    "output_dir=/mnt/ssd/tmp/didemo_prep\n",
    "prefix=frames_300h\n",
    "\n",
    "set -x\n",
    "output_dir=$1\n",
    "prefix=$2\n",
    "if [ -d $output_dir ]; then rm -rf $output_dir; fi\n",
    "mkdir -p $output_dir/all &&\n",
    "for f in $(find ~/ -maxdepth 1 -name $prefix\"*\"); do\n",
    "  tar -xf $f -C $output_dir;\n",
    "done  &&\n",
    "for f in $(find $output_dir -maxdepth 1 -name $prefix\"*\"); do\n",
    "  mv $f/* $output_dir/all/;\n",
    "done  &&\n",
    "cd $output_dir  &&\n",
    "for f in $(find . -maxdepth 1 -name $prefix\"*\"); do\n",
    "  echo rmdir $f;\n",
    "done  &&\n",
    "mv all frames &&\n",
    "tar -cf ~/didemo_$prefix\".tar\" frames/ && cd ~ && echo rm -rf $output_dir\n",
    "```\n",
    "\n",
    "This took less than TBD mins (once it took 20mins but I changed the code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Sanity checks\n",
    "\n",
    "__Note__: In case, all the videos were not dummped, it is important that you generate a text-file with the list of video to process.\n",
    "\n",
    "- Making sure that frames are not empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "dirname = Path('/mnt/ssd/tmp/didemo/frames/frames/')\n",
    "for i in dirname.iterdir():\n",
    "    assert i.is_dir\n",
    "    assert len(os.listdir(i)) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[note] small parentheses. Feel free to ignore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count videos taking care of extensions\n",
      "10642 10642 0\n",
      "Count videos after removing extension\n",
      "10642 10464 178\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "filename = 'data/interim/didemo/frame_extraction/all_videos.txt'\n",
    "df = pd.read_csv(filename, header=None)\n",
    "print('Count videos taking care of extensions')\n",
    "print(len(df), len(df[0].unique()), len(df) - len(df[0].unique()))\n",
    "print('Count videos after removing extension')\n",
    "df2 = df[0].apply(lambda x: os.path.splitext(x)[0])\n",
    "print(len(df2), len(df2.unique()), len(df2) - len(df2.unique()))\n",
    "# Fuck the same video appears with different extensions :S\n",
    "# TODO: check if video length\n",
    "# TODO: check video content manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[conclusion] @escorcia decided to move with the mass because this is considered as \"an engineering practice\" by the community. It would be nice to go deeper in this, but we don't have the bandwidth. We decided to replicate lisa's strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 152\n",
    "\n",
    "1) Generate list of videos or images\n",
    "\n",
    "a. In case, you did not have trouble extracting frames for all videos, you can use the same list\n",
    "\n",
    "```bash\n",
    "ln -s $(pwd)/data/interim/didemo/frame_extraction/videos-* data/interim/didemo/resnet_extraction/\n",
    "```\n",
    "\n",
    "TODO: sample test of code\n",
    "\n",
    "2) Double check that `adobe/extract_resnet.[sh/condor]` are pointitng to the appropriate folders\n",
    "\n",
    "3) Launch job `condor_submit adobe/extract_resnet.condor`\n",
    "\n",
    "4) Monitor\n",
    "\n",
    "- Check nodes\n",
    "\n",
    "!grep \"slot\" log/[prefix]\n",
    "\n",
    "- Check progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> data/interim/didemo/resnet_extraction/0.log <==\n",
      "2018-07-12 23:27:05,743:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-00-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-0', filename='/mnt/ssd/tmp/didemo/resnet152-0.h5', loglevel='INFO')\n",
      "2018-07-12 23:28:47,820:INFO:Successful execution\n",
      "\n",
      "==> data/interim/didemo/resnet_extraction/1.log <==\n",
      "2018-07-12 23:26:34,063:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-01-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-1', filename='/mnt/ssd/tmp/didemo/resnet152-1.h5', loglevel='INFO')\n",
      "2018-07-12 23:28:21,375:INFO:Successful execution\n",
      "\n",
      "==> data/interim/didemo/resnet_extraction/2.log <==\n",
      "2018-07-12 23:47:16,164:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-02-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-2', filename='/mnt/ssd/tmp/didemo/resnet152-2.h5', loglevel='INFO')\n",
      "2018-07-12 23:48:42,697:INFO:Successful execution\n",
      "\n",
      "==> data/interim/didemo/resnet_extraction/3.log <==\n",
      "2018-07-12 23:47:38,095:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-03-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-3', filename='/mnt/ssd/tmp/didemo/resnet152-3.h5', loglevel='INFO')\n",
      "2018-07-12 23:49:07,384:INFO:Successful execution\n",
      "\n",
      "==> data/interim/didemo/resnet_extraction/4.log <==\n",
      "2018-07-12 23:45:40,992:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-04-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-4', filename='/mnt/ssd/tmp/didemo/resnet152-4.h5', loglevel='INFO')\n",
      "2018-07-12 23:47:10,498:INFO:Successful execution\n",
      "\n",
      "==> data/interim/didemo/resnet_extraction/5.log <==\n",
      "2018-07-12 23:48:21,069:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-05-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-5', filename='/mnt/ssd/tmp/didemo/resnet152-5.h5', loglevel='INFO')\n",
      "2018-07-12 23:49:45,707:INFO:Successful execution\n",
      "\n",
      "==> data/interim/didemo/resnet_extraction/6.log <==\n",
      "2018-07-12 23:44:20,823:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-06-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-6', filename='/mnt/ssd/tmp/didemo/resnet152-6.h5', loglevel='INFO')\n",
      "2018-07-12 23:45:46,688:INFO:Successful execution\n",
      "\n",
      "==> data/interim/didemo/resnet_extraction/7.log <==\n",
      "2018-07-12 23:44:29,497:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-07-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-7', filename='/mnt/ssd/tmp/didemo/resnet152-7.h5', loglevel='INFO')\n",
      "2018-07-12 23:45:55,800:INFO:Successful execution\n",
      "\n",
      "==> data/interim/didemo/resnet_extraction/8.log <==\n",
      "2018-07-12 23:24:15,493:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-08-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-8', filename='/mnt/ssd/tmp/didemo/resnet152-8.h5', loglevel='INFO')\n",
      "2018-07-12 23:25:40,135:INFO:Successful execution\n",
      "\n",
      "==> data/interim/didemo/resnet_extraction/9.log <==\n",
      "2018-07-12 23:57:01,819:INFO:Namespace(batch_size=256, compression='gzip', compression_rate=9, csvfile='/mnt/ilcompf9d1/user/escorcia/moments-retrieval/data/interim/didemo/resnet_extraction/videos-09-img.csv', dataset_name='resnet152', dirname='/mnt/ssd/tmp/didemo/resnet152-9', filename='/mnt/ssd/tmp/didemo/resnet152-9.h5', loglevel='INFO')\n",
      "2018-07-12 23:58:33,694:INFO:Successful execution\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 data/interim/didemo/resnet_extraction/*.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Merging HDF5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import h5py\n",
    "\n",
    "filename = '/mnt/ssd/tmp/didemo/features/resnet152_5fps.h5'\n",
    "persistent_file = 'data/interim/didemo/resnet152/320x240_5fps.h5'\n",
    "wildcard = '/mnt/ilcompf9d1/user/escorcia/resnet152-*.h5'\n",
    "\n",
    "with h5py.File(filename, 'w') as fid:\n",
    "    for file_i in glob.glob(wildcard):\n",
    "        with h5py.File(file_i, 'r') as fr:\n",
    "            for _, source_group in fr.items():\n",
    "                fr.copy(source_group, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Coarse average pool per chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 5\n",
    "CHUNK_SIZE = 5  # seconds\n",
    "NUM_CHUNKS = 6\n",
    "filename = '/mnt/ssd/tmp/didemo/features/resnet152_320x240_pooled.h5'\n",
    "dense_file = f'/mnt/ssd/tmp/didemo/features/resnet152_320x240_{FPS}fps.h5'\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(filename, 'w') as fw, h5py.File(dense_file, 'r') as fr:\n",
    "    for video, group_src in fr.items():\n",
    "        # ensure compatibility with MCN code\n",
    "        # MCN code was written for a hdf5 per feature type\n",
    "        # TODO: deprecate this\n",
    "        assert len(list(group_src.keys())) == 1\n",
    "        for name, v in group_src.items():            \n",
    "            feat = v[:]\n",
    "            pooled_feat = np.zeros((NUM_CHUNKS, feat.shape[1]), dtype=feat.dtype)\n",
    "            for i in range(NUM_CHUNKS):\n",
    "                start_ind = i * CHUNK_SIZE * FPS\n",
    "                end_ind = min(start_ind + CHUNK_SIZE * FPS, len(feat))\n",
    "                if start_ind >= len(feat):\n",
    "                    break\n",
    "                pooled_feat[i, :] = feat[start_ind:end_ind, :].mean(axis=0)\n",
    "            fw.create_dataset(video, data=pooled_feat, chunks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[debug] Making sure that copy is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "file1 = '/mnt/ilcompf9d1/user/escorcia/resnet152-0.h5'\n",
    "with h5py.File(filename, 'r') as f1, h5py.File(file1, 'r') as f2:\n",
    "    f1_keys = sorted(list(f1.keys()))\n",
    "    f2_keys = sorted(list(f2.keys()))\n",
    "    assert f1_keys == f2_keys\n",
    "    for i in f1.keys():\n",
    "        f1_i_keys = sorted(list(f1[i].keys()))\n",
    "        f2_i_keys = sorted(list(f2[i].keys()))\n",
    "        assert f1_i_keys == f2_i_keys\n",
    "        for j, v1 in f1[i].items():\n",
    "            x1 = v1[:]\n",
    "            x2 = f2[i][j][:]\n",
    "            np.testing.assert_array_almost_equal(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12572907@N00_2920156258_34d144bf1e.avi 0.36933506\n",
      "12644997@N04_4936603071_9a12b8cc5d.mp4 0.30536875\n",
      "14284621@N06_3944006339_85416993a7.mov 0.3719792\n",
      "16483298@N00_4331364236_f8e7cc40e8.avi 0.42610207\n",
      "16483298@N00_4893184599_197570445d.mp4 0.3697194\n",
      "26292851@N04_4497646769_c867658047.mp4 0.4500945\n",
      "50072196@N00_8243844603_e9a8bf01fe.mov 0.39579678\n",
      "51727341@N00_4913494887_25ba94c153.mp4 0.45705098\n",
      "56424258@N03_8926842688_91c14724ee. 0.44437027\n",
      "67211380@N00_2867483360_731aa9cab3.avi 0.33976325\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "filename = '/mnt/ilcompf9d1/user/escorcia/resnet152-0.h5'\n",
    "fid = h5py.File(filename, 'r')\n",
    "for k, v in fid.items():\n",
    "    print(k, v['resnet152'][:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [legacy] VGG feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging because features where different to those provided by MCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10015567@N08_3655084291_d8b58466fa.mov\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "file1 = '/mnt/ilcompf9d1/user/escorcia/localizing-moments/data/average_fc7.h5'\n",
    "careful = {}\n",
    "with h5py.File(file1, 'r') as f1:\n",
    "    for k, v in f1.items():\n",
    "        feat = v[:]\n",
    "        if feat.sum() != 0:\n",
    "            print(k)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing extracted features with public features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 escorcia 5001 4933094 Jul 11 01:52 /mnt/ilcompf9d1/user/escorcia/tmp_didemo/fc7_subsample10_stock_10015567@N08_3655084291_d8b58466fa.mov.h5\n",
      "(150, 4096)\n",
      "8.976858139038086 0.0\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "filename = '/mnt/ilcompf9d1/user/escorcia/tmp_didemo/fc7_subsample10_stock_44971549@N06_8077235126_bc346362b8.mov.h5'\n",
    "filename = '/mnt/ilcompf9d1/user/escorcia/tmp_didemo/fc7_subsample10_stock_10015567@N08_3655084291_d8b58466fa.mov.h5'\n",
    "!ls -la $filename\n",
    "fid = h5py.File(filename)\n",
    "feat = fid['features'][:]\n",
    "print(feat.shape)\n",
    "print(feat.max(), feat.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not almost equal to 6 decimals\n\n(mismatch 76.025390625%)\n x: array([[0.080325, 0.      , 0.618881, ..., 0.057373, 0.698398, 1.784408],\n       [0.781676, 0.014886, 0.20887 , ..., 0.      , 0.32405 , 0.338488],\n       [1.154795, 0.534264, 0.447821, ..., 0.      , 0.521238, 0.16278 ],...\n y: array([[0.907936, 0.09756 , 0.31482 , ..., 0.022781, 0.594315, 0.259575],\n       [1.023138, 0.467035, 0.362644, ..., 0.15047 , 1.121736, 0.08118 ],\n       [0.813921, 0.272168, 0.244465, ..., 0.245621, 1.05744 , 0.053195],...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3739318f3c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfeat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfeat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_array_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/install/bin/miniconda3/envs/scientific/lib/python3.6/site-packages/numpy/testing/nose_tools/utils.py\u001b[0m in \u001b[0;36massert_array_almost_equal\u001b[0;34m(x, y, decimal, err_msg, verbose)\u001b[0m\n\u001b[1;32m    961\u001b[0m     assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,\n\u001b[1;32m    962\u001b[0m              \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Arrays are not almost equal to %d decimals'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m              precision=decimal)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/install/bin/miniconda3/envs/scientific/lib/python3.6/site-packages/numpy/testing/nose_tools/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    777\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not almost equal to 6 decimals\n\n(mismatch 76.025390625%)\n x: array([[0.080325, 0.      , 0.618881, ..., 0.057373, 0.698398, 1.784408],\n       [0.781676, 0.014886, 0.20887 , ..., 0.      , 0.32405 , 0.338488],\n       [1.154795, 0.534264, 0.447821, ..., 0.      , 0.521238, 0.16278 ],...\n y: array([[0.907936, 0.09756 , 0.31482 , ..., 0.022781, 0.594315, 0.259575],\n       [1.023138, 0.467035, 0.362644, ..., 0.15047 , 1.121736, 0.08118 ],\n       [0.813921, 0.272168, 0.244465, ..., 0.245621, 1.05744 , 0.053195],..."
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "file1 = '/mnt/ilcompf9d1/user/escorcia/localizing-moments/data/average_fc7.h5'\n",
    "file2 = '/mnt/ilcompf9d1/user/escorcia/tmp_didemo/average_fc7.h5'\n",
    "\n",
    "with h5py.File(file1, 'r') as f1, h5py.File(file2, 'r') as f2:\n",
    "    video_id = list(f2.keys())[0]\n",
    "    feat2 = f2[video_id][:]\n",
    "    feat1 = f1[video_id][:]\n",
    "    np.testing.assert_array_almost_equal(feat1, feat2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
