{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic clean-up of YFCC100M by Nearest neighbors\n",
    "\n",
    "Select a subset of images from YFCC100M that look similar to moments in DIDEMO in feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image features: 175.57180213928223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/437 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking features: 188.22845602035522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437/437 [01:44<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 105.02398562431335\n"
     ]
    }
   ],
   "source": [
    "image_csv = '../data/interim/yfcc100m/001.csv'\n",
    "didemo_jsons = ['../data/raw/train_data.json',\n",
    "                '../data/raw/val_data.json']\n",
    "nouns2video_json = '../data/interim/didemo/nouns_to_video.json'\n",
    "image_h5 = '../data/interim/yfcc100m/resnet152/320x240_001.h5'\n",
    "video_h5 = '../data/interim/didemo/resnet152/320x240_max.h5'\n",
    "IMAGES_PER_TAG = 100\n",
    "\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TODO. unit-norm features\n",
    "class MomentDescriptor():\n",
    "    def __init__(self, filename):\n",
    "        self.file = filename\n",
    "        \n",
    "    def __call__(self, video, time):\n",
    "        start, end = time\n",
    "        end += 1\n",
    "        with h5py.File(self.file, 'r') as fid:\n",
    "            feature = fid[video][:]\n",
    "            # TODO: try max?\n",
    "            descriptor = feature[start:end, :].mean(axis=0)\n",
    "        return descriptor\n",
    "    \n",
    "def load_image_features(filename):\n",
    "    feat_db_list = []\n",
    "    end = time.time()\n",
    "    with h5py.File(filename, 'r') as fid:\n",
    "        for _, v in fid.items():\n",
    "            feat_db_list.append(v[:])\n",
    "    print(f'Loaded image features: {time.time() - end}')\n",
    "    feat_db = np.stack(feat_db_list).squeeze()\n",
    "    print(f'Stacking features: {time.time() - end}')\n",
    "    return feat_db\n",
    "\n",
    "# get videos in train-val\n",
    "didemo_videos = set()\n",
    "for filename in didemo_jsons:\n",
    "    with open(filename, 'r') as fid:\n",
    "        status = [didemo_videos.add(moment['video'])\n",
    "                  for moment in json.load(fid)]\n",
    "\n",
    "# mapping of NOUNs to didemo videos\n",
    "with open(nouns2video_json, 'r') as fid:\n",
    "    didemo_nouns2video = json.load(fid)\n",
    "        \n",
    "get_descriptor = MomentDescriptor(video_h5)\n",
    "\n",
    "df_yfcc100m = pd.read_csv(image_csv)\n",
    "image_descriptors = load_image_features(image_h5)\n",
    "\n",
    "# TODO: generalize it?. It assumes a single top-1 tag\n",
    "clean_idxs = []\n",
    "end = time.time()\n",
    "debug = []\n",
    "for tag, df_i in tqdm(df_yfcc100m.groupby('topk_tags')):\n",
    "    assert tag in didemo_nouns2video['nouns']\n",
    "    moments_videos = didemo_nouns2video['videos'][tag]\n",
    "    moments_time = didemo_nouns2video['time'][tag]\n",
    "    assert len(moments_videos) == len(moments_time)\n",
    "\n",
    "    moment_idxs = []\n",
    "    for j, video_j in enumerate(moments_videos):\n",
    "        if video_j not in didemo_videos:\n",
    "            continue\n",
    "        moment_idxs.append(j)\n",
    "    n_per_j = IMAGES_PER_TAG // len(moment_idxs)\n",
    "    \n",
    "    idxs_i = df_i.index\n",
    "    clean_idxs_i = set()\n",
    "    # TODO. use pdist2.\n",
    "    for j in moment_idxs:\n",
    "        moment_j = get_descriptor(moments_videos[j], moments_time[j])\n",
    "        # TODO. study purite checking overall NN.\n",
    "        image_descriptors_i = image_descriptors[idxs_i, :]\n",
    "        # TODO. other distances?\n",
    "        distance = ((image_descriptors_i - moment_j)**2).sum(axis=1)\n",
    "        idxs_sorted = distance.argsort()\n",
    "        # TODO. fancy selections based on bipartite graph stuff\n",
    "        # I was tired so...\n",
    "        # Add n_per_j most similar images to moment_j taking into account\n",
    "        # that other moments could have added the same image\n",
    "        n_before = len(clean_idxs_i)\n",
    "        idx_start, idx_end = 0, n_per_j\n",
    "        while True:\n",
    "            blah = idxs_i[idxs_sorted[idx_start:idx_end]]\n",
    "            clean_idxs_i.update(blah)\n",
    "            idx_start += len(blah)\n",
    "            items_added = len(clean_idxs_i) - n_before\n",
    "            if items_added == n_per_j:\n",
    "                break\n",
    "            else:\n",
    "                idx_end += n_per_j - items_added\n",
    "            idx_end = min(idx_end, len(idxs_sorted))\n",
    "            if idx_start > len(idxs_i) or idx_end - idx_start <= 0:\n",
    "                break\n",
    "        \n",
    "        if random.random() < 0.01:\n",
    "            debug.append((moments_videos[j], moments_time[j], tag, df_i.loc[idxs_i[idxs_sorted[:5]], 'url']))\n",
    "    clean_idxs.extend(clean_idxs_i)\n",
    "print(f'Cleaning: {time.time() - end}')\n",
    "\n",
    "clean_df = df_yfcc100m.loc[clean_idxs, :]\n",
    "raise\n",
    "clean_df.to_csv('../data/interim/yfcc100m/002.csv', index=None)\n",
    "# damm there are so many degrees of freedom, definetily I can't reject the hypothesis\n",
    "# only conclude that I'm unlucky and not smart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize top-5 neighbors for a given moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ind = 7\n",
    "if ind >= len(debug):\n",
    "    print(f'Max ind is: {len(debug) - 1}')\n",
    "    raise\n",
    "from IPython.display import Image, display, HTML\n",
    "print(debug[ind][2], (debug[ind][1][0] * 5, debug[ind][1][1] * 5 + 5) )\n",
    "video_url = '/'.join(debug[ind][0].split('_')[:2])\n",
    "EMBED_VIDEO = (\n",
    "    '<a data-flickr-embed=\"true\" data-context=\"true\" href=\"https://'\n",
    "    f'www.flickr.com/photos/{video_url}/in/photostream/\"> <img src='\n",
    "    '\"https://farm4.staticflickr.com/3259/2408598493_655c93f5f9.jpg\"'\n",
    "    ' width=\"320\" height=\"240\" alt=\"2005_03_13__11_28_05\"></a><script'\n",
    "    ' async src=\"//embedr.flickr.com/assets/client-code.js\" charset='\n",
    "    '\"utf-8\"></script>'\n",
    ")\n",
    "display(HTML(EMBED_VIDEO))\n",
    "for i in debug[ind][-1]:\n",
    "    display(Image(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
