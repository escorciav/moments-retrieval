{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic clean-up of YFCC100M by Nearest neighbors\n",
    "\n",
    "Select a subset of images from YFCC100M that look similar to moments in DIDEMO in feature space.\n",
    "\n",
    "## S1. Neighbors among images picked for a given tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_csv = '../data/interim/yfcc100m/001.csv'\n",
    "didemo_jsons = ['../data/raw/train_data.json',\n",
    "                '../data/raw/val_data.json']\n",
    "nouns2video_json = '../data/interim/didemo/nouns_to_video.json'\n",
    "image_h5 = '../data/interim/yfcc100m/resnet152/320x240_001.h5'\n",
    "video_h5 = '../data/interim/didemo/resnet152/320x240_max.h5'\n",
    "IMAGES_PER_TAG = 100\n",
    "\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TODO. unit-norm features\n",
    "class MomentDescriptor():\n",
    "    def __init__(self, filename):\n",
    "        self.file = filename\n",
    "        \n",
    "    def __call__(self, video, time):\n",
    "        start, end = time\n",
    "        end += 1\n",
    "        with h5py.File(self.file, 'r') as fid:\n",
    "            feature = fid[video][:]\n",
    "            # TODO: try max?\n",
    "            descriptor = feature[start:end, :].mean(axis=0)\n",
    "        return descriptor\n",
    "    \n",
    "def load_image_features(filename):\n",
    "    feat_db_list = []\n",
    "    end = time.time()\n",
    "    with h5py.File(filename, 'r') as fid:\n",
    "        for _, v in fid.items():\n",
    "            feat_db_list.append(v[:])\n",
    "    print(f'Loaded image features: {time.time() - end}')\n",
    "    feat_db = np.stack(feat_db_list).squeeze()\n",
    "    print(f'Stacking features: {time.time() - end}')\n",
    "    return feat_db\n",
    "\n",
    "# get videos in train-val\n",
    "didemo_videos = set()\n",
    "for filename in didemo_jsons:\n",
    "    with open(filename, 'r') as fid:\n",
    "        status = [didemo_videos.add(moment['video'])\n",
    "                  for moment in json.load(fid)]\n",
    "\n",
    "# mapping of NOUNs to didemo videos\n",
    "with open(nouns2video_json, 'r') as fid:\n",
    "    didemo_nouns2video = json.load(fid)\n",
    "        \n",
    "get_descriptor = MomentDescriptor(video_h5)\n",
    "\n",
    "df_yfcc100m = pd.read_csv(image_csv)\n",
    "image_descriptors = load_image_features(image_h5)\n",
    "\n",
    "# TODO: generalize it?. It assumes a single top-1 tag\n",
    "clean_idxs = []\n",
    "end = time.time()\n",
    "debug = []\n",
    "for tag, df_i in tqdm(df_yfcc100m.groupby('topk_tags')):\n",
    "    assert tag in didemo_nouns2video['nouns']\n",
    "    moments_videos = didemo_nouns2video['videos'][tag]\n",
    "    moments_time = didemo_nouns2video['time'][tag]\n",
    "    assert len(moments_videos) == len(moments_time)\n",
    "\n",
    "    moment_idxs = []\n",
    "    for j, video_j in enumerate(moments_videos):\n",
    "        if video_j not in didemo_videos:\n",
    "            continue\n",
    "        moment_idxs.append(j)\n",
    "    n_per_j = IMAGES_PER_TAG // len(moment_idxs)\n",
    "    \n",
    "    idxs_i = df_i.index\n",
    "    clean_idxs_i = set()\n",
    "    # TODO. use pdist2.\n",
    "    for j in moment_idxs:\n",
    "        moment_j = get_descriptor(moments_videos[j], moments_time[j])\n",
    "        # TODO. study purite checking overall NN.\n",
    "        image_descriptors_i = image_descriptors[idxs_i, :]\n",
    "        # TODO. other distances?\n",
    "        distance = ((image_descriptors_i - moment_j)**2).sum(axis=1)\n",
    "        idxs_sorted = distance.argsort()\n",
    "        # TODO. fancy selections based on bipartite graph stuff\n",
    "        # I was tired so...\n",
    "        # Add n_per_j most similar images to moment_j taking into account\n",
    "        # that other moments could have added the same image\n",
    "        n_before = len(clean_idxs_i)\n",
    "        idx_start, idx_end = 0, n_per_j\n",
    "        while True:\n",
    "            blah = idxs_i[idxs_sorted[idx_start:idx_end]]\n",
    "            clean_idxs_i.update(blah)\n",
    "            idx_start += len(blah)\n",
    "            items_added = len(clean_idxs_i) - n_before\n",
    "            if items_added == n_per_j:\n",
    "                break\n",
    "            else:\n",
    "                idx_end += n_per_j - items_added\n",
    "            idx_end = min(idx_end, len(idxs_sorted))\n",
    "            if idx_start > len(idxs_i) or idx_end - idx_start <= 0:\n",
    "                break\n",
    "        \n",
    "        if random.random() < 0.01:\n",
    "            debug.append((moments_videos[j], moments_time[j], tag, df_i.loc[idxs_i[idxs_sorted[:5]], 'url']))\n",
    "    clean_idxs.extend(clean_idxs_i)\n",
    "print(f'Cleaning: {time.time() - end}')\n",
    "\n",
    "clean_df = df_yfcc100m.loc[clean_idxs, :]\n",
    "raise\n",
    "clean_df.to_csv('../data/interim/yfcc100m/002.csv', index=None)\n",
    "# damm there are so many degrees of freedom, definetily I can't reject the hypothesis\n",
    "# only conclude that I'm unlucky and not smart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2. Neighbors among entire image subset\n",
    "\n",
    "Find 500 nearest neighbors image over the entire dataset, but only retain those where the NOUNs was tagged to the image. In a nutshell, similar to the above procedure but switching stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_csv = '../data/interim/yfcc100m/001.csv'\n",
    "didemo_jsons = ['../data/raw/train_data.json',\n",
    "                '../data/raw/val_data.json']\n",
    "nouns2video_json = '../data/interim/didemo/nouns_to_video.json'\n",
    "image_h5 = '../data/interim/yfcc100m/resnet152/320x240_001.h5'\n",
    "video_h5 = '../data/interim/didemo/resnet152/320x240_max.h5'\n",
    "IMAGES_PER_TAG = 100\n",
    "RELAX_FACTOR = 5\n",
    "MINIMORUM = 75\n",
    "MODE = 1\n",
    "OUTPUT_FILE = f'../data/interim/yfcc100m/003-{RELAX_FACTOR}-{MODE}.csv'\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TODO. unit-norm features\n",
    "class MomentDescriptor():\n",
    "    def __init__(self, filename):\n",
    "        self.file = filename\n",
    "        \n",
    "    def __call__(self, video, time):\n",
    "        start, end = time\n",
    "        end += 1\n",
    "        with h5py.File(self.file, 'r') as fid:\n",
    "            feature = fid[video][:]\n",
    "            # TODO: try max?\n",
    "            descriptor = feature[start:end, :].mean(axis=0)\n",
    "        return descriptor\n",
    "    \n",
    "    def get_features(self, videos, times):\n",
    "        assert len(videos) == len(times)\n",
    "        descriptors = []\n",
    "        with h5py.File(self.file, 'r') as fid:\n",
    "            for i, video_i in enumerate(videos):\n",
    "                feature_i = fid[video_i][:]\n",
    "                start, end = times[i]\n",
    "                end += 1\n",
    "                descriptors.append(feature_i[start:end, :].mean(axis=0, keepdims=True))\n",
    "        descriptors = np.concatenate(descriptors, axis=0)\n",
    "        return descriptors\n",
    "    \n",
    "def load_image_features(filename, id_list):\n",
    "    feat_db_list = []\n",
    "    end = time.time()\n",
    "    with h5py.File(filename, 'r') as fid:\n",
    "        for v in id_list:\n",
    "            feat_db_list.append(fid[v][:])\n",
    "    print(f'Loaded image features: {time.time() - end}')\n",
    "    end = time.time()\n",
    "    feat_db = np.stack(feat_db_list).squeeze()\n",
    "    print(f'Stacking features: {time.time() - end}')\n",
    "    return feat_db\n",
    "\n",
    "# get videos in train-val\n",
    "didemo_videos = set()\n",
    "didemo_moments = {}\n",
    "for filename in didemo_jsons:\n",
    "    with open(filename, 'r') as fid:\n",
    "        for moment in json.load(fid):\n",
    "            didemo_videos.add(moment['video'])\n",
    "            moment_id = moment['annotation_id']\n",
    "            didemo_moments[moment_id] = moment \n",
    "\n",
    "# mapping of NOUNs to didemo videos\n",
    "with open(nouns2video_json, 'r') as fid:\n",
    "    didemo_nouns2video = json.load(fid)\n",
    "        \n",
    "get_descriptor = MomentDescriptor(video_h5)\n",
    "\n",
    "df_yfcc100m = pd.read_csv(image_csv)\n",
    "df_yfcc100m.loc[:, 'tags'] = df_yfcc100m.loc[:, 'tags'].apply(lambda x: x + ';')\n",
    "image_descriptors = load_image_features(image_h5, df_yfcc100m['h5_id'].tolist())\n",
    "\n",
    "end = time.time()\n",
    "image_tree = cKDTree(image_descriptors)\n",
    "print(f'Building tree: {time.time() - end}')\n",
    "end = time.time()\n",
    "\n",
    "clean_idxs = set()\n",
    "debug = []\n",
    "chekalebn = []\n",
    "for tag, _ in tqdm(df_yfcc100m.groupby('topk_tags')):\n",
    "    assert tag in didemo_nouns2video['nouns']\n",
    "    moments_videos = didemo_nouns2video['videos'][tag]\n",
    "    moments_time = didemo_nouns2video['time'][tag]\n",
    "    # DEBUG: get description\n",
    "    assert len(moments_videos) == len(moments_time)\n",
    "    \n",
    "    moment_idxs = [j for j, video_j in enumerate(moments_videos)\n",
    "                   if video_j in didemo_videos]\n",
    "    n_per_j = (IMAGES_PER_TAG * RELAX_FACTOR) // len(moment_idxs)\n",
    "\n",
    "    clean_idxs_i = set()\n",
    "    for j in moment_idxs:\n",
    "        moment_j = get_descriptor(moments_videos[j], moments_time[j])\n",
    "        distance_j, ind_j = image_tree.query(moment_j, k=n_per_j, n_jobs=-1)\n",
    "        # filter by tag\n",
    "        if MODE == 0:\n",
    "            pick_j = df_yfcc100m.loc[ind_j, 'topk_tags'] == tag\n",
    "        elif MODE == 1:\n",
    "            pick_j = df_yfcc100m.loc[ind_j, 'tags'].apply(lambda x: tag in x)\n",
    "        else:\n",
    "            raise\n",
    "        clean_idxs_i.update(ind_j[pick_j].tolist())\n",
    "        \n",
    "        if random.random() < 0.01 and len(pick_j) > 0:\n",
    "            debug.append((moments_videos[j],\n",
    "                          moments_time[j],\n",
    "                          tag,\n",
    "                          df_i.loc[ind_j[pick_j[:min(5, len(pick_j))]], 'url'],\n",
    "                          )\n",
    "                        )\n",
    "    if len(clean_idxs_i) >= MINIMORUM:\n",
    "        clean_idxs_i = list(clean_idxs_i)\n",
    "        clean_idxs.update(clean_idxs_i[:min(IMAGES_PER_TAG, len(clean_idxs_i))])\n",
    "    chekalebn.append(len(clean_idxs_i))\n",
    "    \n",
    "    # Abort this path because scipy-hungarian was taking a lot of time\n",
    "#     # Pull descriptors from train/val videos\n",
    "#     video_descriptors = get_descriptor.get_features(\n",
    "#         *zip(*[(video_i, moments_time[i])\n",
    "#                for i, video_i in enumerate(moments_videos)\n",
    "#                if video_i in didemo_videos\n",
    "#               ]\n",
    "#             )\n",
    "#     )    \n",
    "    # TODO: switch to cosine distance\n",
    "#     dist_matrix = cdist(video_descriptors, image_descriptors)\n",
    "#     extra = ((IMAGES_PER_TAG * RELAX_FACTOR) // len(dist_matrix)) + 1\n",
    "#     dist_matrix = np.tile(dist_matrix, [extra, 1])\n",
    "#     aja, cev = linear_sum_assignment(dist_matrix)\n",
    "\n",
    "clean_df = df_yfcc100m.loc[clean_idxs, :]\n",
    "with open(OUTPUT_FILE, 'x') as fid:\n",
    "    clean_df.to_csv(fid, index=None)\n",
    "with open(OUTPUT_FILE.replace('.csv', '.json'), 'x') as fid:\n",
    "    json.dump({'len_per_tag': chekalebn,\n",
    "               'dataset_size': len(clean_idxs),\n",
    "               'debug_instances': debug,\n",
    "              },\n",
    "              fid)\n",
    "# damm there are so many degrees of freedom, definetily I can't reject the hypothesis\n",
    "# only conclude that I'm unlucky and not smart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profiling\n",
    "\n",
    "man, that thing was taking so much time, so @escorcia spends some time figuring out what was going on. The results are below, it seems that we hit the wall.\n",
    "\n",
    "gotta the meisters, if that's what we wanna do 😕\n",
    "\n",
    "<img src=\"https://static1.squarespace.com/static/5160bb45e4b0e13a258812c8/t/5549542ae4b04cef2f6cd895/1430869036049/?format=750w\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_CSV = '../data/interim/yfcc100m/001.csv'\n",
    "DIDEMO_JSONS = ['../data/raw/train_data.json',\n",
    "                '../data/raw/val_data.json']\n",
    "NOUNS2VIDEO_JSON = '../data/interim/didemo/nouns_to_video.json'\n",
    "image_h5 = '../data/interim/yfcc100m/resnet152/320x240_001.h5'\n",
    "video_h5 = '../data/interim/didemo/resnet152/320x240_max.h5'\n",
    "IMAGES_PER_TAG = 100\n",
    "RELAX_FACTOR = 100\n",
    "MINIMORUM = 75\n",
    "MODE = 0\n",
    "OUTPUT_FILE = f'../data/interim/yfcc100m/003-{RELAX_FACTOR}-{MODE}.csv'\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "class MomentDescriptor():\n",
    "    def __init__(self, filename):\n",
    "        self.file = filename\n",
    "        \n",
    "    def __call__(self, video, time):\n",
    "        start, end = time\n",
    "        end += 1\n",
    "        with h5py.File(self.file, 'r') as fid:\n",
    "            feature = fid[video][:]\n",
    "            # TODO: try max?\n",
    "            descriptor = feature[start:end, :].mean(axis=0)\n",
    "        return descriptor\n",
    "    \n",
    "    def get_features(self, videos, times):\n",
    "        assert len(videos) == len(times)\n",
    "        descriptors = []\n",
    "        with h5py.File(self.file, 'r') as fid:\n",
    "            for i, video_i in enumerate(videos):\n",
    "                feature_i = fid[video_i][:]\n",
    "                start, end = times[i]\n",
    "                end += 1\n",
    "                descriptors.append(feature_i[start:end, :].mean(axis=0, keepdims=True))\n",
    "        descriptors = np.concatenate(descriptors, axis=0)\n",
    "        return descriptors\n",
    "    \n",
    "def load_image_features(filename, id_list):\n",
    "    feat_db_list = []\n",
    "    with h5py.File(filename, 'r') as fid:\n",
    "        for v in id_list:\n",
    "            feat_db_list.append(fid[v][:])\n",
    "    feat_db = np.stack(feat_db_list).squeeze()\n",
    "    return feat_db\n",
    "\n",
    "def get_videos_of_interest(files):\n",
    "    videos = set()\n",
    "    moments = {}\n",
    "    for filename in files:\n",
    "        with open(filename, 'r') as fid:\n",
    "            for moment in json.load(fid):\n",
    "                videos.add(moment['video'])\n",
    "                moment_id = moment['annotation_id']\n",
    "                moments[moment_id] = moment \n",
    "    return videos, moments\n",
    "\n",
    "def load_didemo_nouns_metadata(filename):\n",
    "    # mapping of NOUNs to didemo videos\n",
    "    with open(filename, 'r') as fid:\n",
    "        return json.load(fid)\n",
    "    \n",
    "def get_indices_of_moi(whitelist, video_list):\n",
    "    # only consider videos in whitelist\n",
    "    return [j for j, video_j in enumerate(video_list)\n",
    "            if video_j in whitelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def honorable_cev():\n",
    "    didemo_videos, didemo_moments = get_videos_of_interest(DIDEMO_JSONS)\n",
    "    didemo_nouns2video = load_didemo_nouns_metadata(NOUNS2VIDEO_JSON)\n",
    "    get_descriptor = MomentDescriptor(video_h5)\n",
    "\n",
    "    df_yfcc100m = pd.read_csv(IMAGE_CSV)\n",
    "    df_yfcc100m.loc[:, 'tags'] = df_yfcc100m.loc[:, 'tags'].apply(lambda x: x + ';')\n",
    "    image_descriptors = load_image_features(image_h5, df_yfcc100m['h5_id'].tolist())\n",
    "\n",
    "    image_tree = cKDTree(image_descriptors)\n",
    "\n",
    "    clean_idxs = set()\n",
    "    debug = []\n",
    "    chekalebn = []\n",
    "    counter = 0\n",
    "    end = time.time()\n",
    "    for tag, _ in df_yfcc100m.groupby('topk_tags'):\n",
    "        assert tag in didemo_nouns2video['nouns']\n",
    "        moments_videos = didemo_nouns2video['videos'][tag]\n",
    "        moments_time = didemo_nouns2video['time'][tag]\n",
    "        assert len(moments_videos) == len(moments_time) \n",
    "        moment_idxs = get_indices_of_moi(didemo_videos, moments_videos)\n",
    "        n_per_j = (IMAGES_PER_TAG * RELAX_FACTOR) // len(moment_idxs)\n",
    "\n",
    "        clean_idxs_i = set()\n",
    "        for j in moment_idxs:\n",
    "            counter += 1\n",
    "\n",
    "            moment_j = get_descriptor(moments_videos[j], moments_time[j])\n",
    "            distance_j, ind_j = image_tree.query(moment_j, k=n_per_j, n_jobs=-1)\n",
    "            # filter by tag\n",
    "            if MODE == 0:\n",
    "                pick_j = df_yfcc100m.loc[ind_j, 'topk_tags'] == tag\n",
    "            elif MODE == 1:\n",
    "                pick_j = df_yfcc100m.loc[ind_j, 'tags'].apply(lambda x: tag in x)\n",
    "            else:\n",
    "                raise\n",
    "            clean_idxs_i.update(ind_j[pick_j].tolist())\n",
    "\n",
    "            if random.random() < 0.01 and len(pick_j) > 0:\n",
    "                debug.append((moments_videos[j],\n",
    "                              moments_time[j],\n",
    "                              tag,\n",
    "                              df_yfcc100m.loc[ind_j[pick_j], 'url'].iloc[:min(5, pick_j.sum())],\n",
    "                              )\n",
    "                            )\n",
    "        if len(clean_idxs_i) >= MINIMORUM:\n",
    "            clean_idxs_i = list(clean_idxs_i)\n",
    "            clean_idxs.update(clean_idxs_i[:min(IMAGES_PER_TAG, len(clean_idxs_i))])\n",
    "        chekalebn.append(len(clean_idxs_i))\n",
    "        if counter == 100:\n",
    "            break\n",
    "        if counter % 10:\n",
    "            print(counter, time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    clean_df = df_yfcc100m.loc[clean_idxs, :]\n",
    "    with open(OUTPUT_FILE, 'x') as fid:\n",
    "        clean_df.to_csv(fid, index=None)\n",
    "    with open(OUTPUT_FILE.replace('.csv', '.json'), 'x') as fid:\n",
    "        json.dump({'len_per_tag': chekalebn,\n",
    "                   'dataset_size': len(clean_idxs),\n",
    "                   'debug_instances': debug,\n",
    "                  },\n",
    "                  fid)\n",
    "    # damm there are so many degrees of freedom, definetily I can't reject the hypothesis\n",
    "    # only conclude that I'm unlucky and not smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 2825.31 s\n",
       "File: <ipython-input-2-1865751d39d6>\n",
       "Function: honorable_cev at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def honorable_cev():\n",
       "     2         1     381430.0 381430.0      0.0      didemo_videos, didemo_moments = get_videos_of_interest(DIDEMO_JSONS)\n",
       "     3         1     228510.0 228510.0      0.0      didemo_nouns2video = load_didemo_nouns_metadata(NOUNS2VIDEO_JSON)\n",
       "     4         1         14.0     14.0      0.0      get_descriptor = MomentDescriptor(video_h5)\n",
       "     5                                           \n",
       "     6         1    2425621.0 2425621.0      0.1      df_yfcc100m = pd.read_csv(IMAGE_CSV)\n",
       "     7         1     249944.0 249944.0      0.0      df_yfcc100m.loc[:, 'tags'] = df_yfcc100m.loc[:, 'tags'].apply(lambda x: x + ';')\n",
       "     8         1  195611099.0 195611099.0      6.9      image_descriptors = load_image_features(image_h5, df_yfcc100m['h5_id'].tolist())\n",
       "     9                                           \n",
       "    10         1  143379064.0 143379064.0      5.1      image_tree = cKDTree(image_descriptors)\n",
       "    11                                           \n",
       "    12         1         13.0     13.0      0.0      clean_idxs = set()\n",
       "    13         1          5.0      5.0      0.0      debug = []\n",
       "    14         1          2.0      2.0      0.0      chekalebn = []\n",
       "    15         1          2.0      2.0      0.0      counter = 0\n",
       "    16        12     104900.0   8741.7      0.0      for tag, _ in df_yfcc100m.groupby('topk_tags'):\n",
       "    17        12        115.0      9.6      0.0          assert tag in didemo_nouns2video['nouns']\n",
       "    18        12         95.0      7.9      0.0          moments_videos = didemo_nouns2video['videos'][tag]\n",
       "    19        12         86.0      7.2      0.0          moments_time = didemo_nouns2video['time'][tag]\n",
       "    20                                                   # TODO (debug): get description\n",
       "    21        12         23.0      1.9      0.0          assert len(moments_videos) == len(moments_time) \n",
       "    22        12        992.0     82.7      0.0          moment_idxs = get_indices_of_moi(didemo_videos, moments_videos)\n",
       "    23        12         28.0      2.3      0.0          n_per_j = (IMAGES_PER_TAG * RELAX_FACTOR) // len(moment_idxs)\n",
       "    24                                           \n",
       "    25        12         40.0      3.3      0.0          clean_idxs_i = set()\n",
       "    26       488       1114.0      2.3      0.0          for j in moment_idxs:\n",
       "    27       477        878.0      1.8      0.0              counter += 1\n",
       "    28                                           \n",
       "    29       477    1263362.0   2648.6      0.0              moment_j = get_descriptor(moments_videos[j], moments_time[j])\n",
       "    30       477 2480234985.0 5199654.1     87.8              distance_j, ind_j = image_tree.query(moment_j, k=n_per_j, n_jobs=-1)\n",
       "    31                                                       # filter by tag\n",
       "    32       476       2191.0      4.6      0.0              if MODE == 0:\n",
       "    33                                                           pick_j = df_yfcc100m.loc[ind_j, 'topk_tags'] == tag\n",
       "    34       476        875.0      1.8      0.0              elif MODE == 1:\n",
       "    35       476    1389679.0   2919.5      0.0                  pick_j = df_yfcc100m.loc[ind_j, 'tags'].apply(lambda x: tag in x)\n",
       "    36                                                       else:\n",
       "    37                                                           raise\n",
       "    38       476      21541.0     45.3      0.0              clean_idxs_i.update(ind_j[pick_j].tolist())\n",
       "    39                                           \n",
       "    40       476       3902.0      8.2      0.0              if random.random() < 0.01 and len(pick_j) > 0:\n",
       "    41         4         17.0      4.2      0.0                  debug.append((moments_videos[j],\n",
       "    42         4         13.0      3.2      0.0                                moments_time[j],\n",
       "    43         4          6.0      1.5      0.0                                tag,\n",
       "    44         4       6485.0   1621.2      0.0                                df_yfcc100m.loc[ind_j[pick_j], 'url'].iloc[:min(5, pick_j.sum())],\n",
       "    45                                                                         )\n",
       "    46                                                                       )\n",
       "    47        11         19.0      1.7      0.0          if len(clean_idxs_i) >= MINIMORUM:\n",
       "    48         7        146.0     20.9      0.0              clean_idxs_i = list(clean_idxs_i)\n",
       "    49         7        103.0     14.7      0.0              clean_idxs.update(clean_idxs_i[:min(IMAGES_PER_TAG, len(clean_idxs_i))])\n",
       "    50        11         23.0      2.1      0.0          chekalebn.append(len(clean_idxs_i))\n",
       "    51        11         19.0      1.7      0.0          if counter == 1000:\n",
       "    52                                                       break\n",
       "    53                                           \n",
       "    54                                               clean_df = df_yfcc100m.loc[clean_idxs, :]\n",
       "    55                                               with open(OUTPUT_FILE, 'x') as fid:\n",
       "    56                                                   clean_df.to_csv(fid, index=None)\n",
       "    57                                               with open(OUTPUT_FILE.replace('.csv', '.json'), 'x') as fid:\n",
       "    58                                                   json.dump({'len_per_tag': chekalebn,\n",
       "    59                                                              'dataset_size': len(clean_idxs),\n",
       "    60                                                              'debug_instances': debug,\n",
       "    61                                                             },\n",
       "    62                                                             fid)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -s -f honorable_cev honorable_cev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize top-5 neighbors for a given moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell if using S2, given that the initial NN implementation is not approximate and takes so much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable of NOUNs: 175\n",
      "Dataset size: 16037\n"
     ]
    }
   ],
   "source": [
    "MINIMORUM = 75\n",
    "filename = '../data/interim/yfcc100m/003-25-1.json'\n",
    "\n",
    "import json\n",
    "with open(filename, 'r') as fid:\n",
    "    data = json.load(fid)\n",
    "debug = data['debug_instances']\n",
    "print('Trainable of NOUNs:',\n",
    "      len([i for i in data['len_per_tag'] if i >= MINIMORUM]))\n",
    "print('Dataset size:', data['dataset_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ind = 19\n",
    "if ind >= len(debug):\n",
    "    print(f'Max ind is: {len(debug) - 1}')\n",
    "    raise\n",
    "from IPython.display import Image, display, HTML\n",
    "print(debug[ind][2], (debug[ind][1][0] * 5, debug[ind][1][1] * 5 + 5) )\n",
    "video_url = '/'.join(debug[ind][0].split('_')[:2])\n",
    "EMBED_VIDEO = (\n",
    "    '<a data-flickr-embed=\"true\" data-context=\"true\" href=\"https://'\n",
    "    f'www.flickr.com/photos/{video_url}/in/photostream/\"> <img src='\n",
    "    '\"https://farm4.staticflickr.com/3259/2408598493_655c93f5f9.jpg\"'\n",
    "    ' width=\"320\" height=\"240\" alt=\"2005_03_13__11_28_05\"></a><script'\n",
    "    ' async src=\"//embedr.flickr.com/assets/client-code.js\" charset='\n",
    "    '\"utf-8\"></script>'\n",
    ")\n",
    "display(HTML(EMBED_VIDEO))\n",
    "for i in debug[ind][-1]:\n",
    "    display(Image(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
