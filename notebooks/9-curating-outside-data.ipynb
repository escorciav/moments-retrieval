{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiDeMo data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect and count all `NOUN`s form DiDeMo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "# Count will be dumped here\n",
    "filename = 'data/interim/didemo/nouns_count.csv'\n",
    "# Make sure you downloaded DiDeMo data and place it in\n",
    "# data/raw/{}_data.json\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "subsets = ['train', 'val', 'test']\n",
    "num_descriptions = 0\n",
    "didemo_nouns = Counter()\n",
    "for subset in subsets:\n",
    "    filename = f'data/raw/{subset}_data.json'\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    for d in data:\n",
    "        num_descriptions += 1\n",
    "        d_i = d['description']\n",
    "        doc_i = nlp(d_i)\n",
    "        doc_i_nouns = Counter()\n",
    "        for token in doc_i:\n",
    "            if token.pos_ == 'NOUN':\n",
    "                doc_i_nouns.update({token.lemma_: 1})\n",
    "        didemo_nouns.update(doc_i_nouns)\n",
    "print('Number of descriptions', num_descriptions)\n",
    "print('Number of NOUNs', len(didemo_nouns))\n",
    "\n",
    "# Comment the following lines if you are not interested in\n",
    "# dumping CSV with counts of NOUNs\n",
    "with open(filename, 'x') as fid:\n",
    "    fid.write('tag,count\\n')\n",
    "    for i in didemo_nouns.most_common():\n",
    "        fid.write(f'{i[0]},{i[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map NOUN to videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "# Count will be dumped here\n",
    "filename = 'data/interim/didemo/nouns_to_videos.json'\n",
    "# Make sure you downloaded DiDeMo data and place it in\n",
    "# data/raw/{}_data.json\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "subsets = ['train', 'val', 'test']\n",
    "num_descriptions = 0\n",
    "didemo_nouns = Counter()\n",
    "videos = {}\n",
    "time = {}\n",
    "for subset in subsets:\n",
    "    filename = f'data/raw/{subset}_data.json'\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    for d in data:\n",
    "        num_descriptions += 1\n",
    "        d_i = d['description']\n",
    "        doc_i = nlp(d_i)\n",
    "        doc_i_nouns = Counter()\n",
    "        for token in doc_i:\n",
    "            if token.pos_ == 'NOUN':\n",
    "                doc_i_nouns.update({token.lemma_: 1})\n",
    "                random.shuffle(d['times'])\n",
    "                time_i = d['times'][0]\n",
    "                time_i[0] *= 5\n",
    "                time_i[1] *= 5\n",
    "                time_i[1] += 5\n",
    "                if token.lemma_ in videos:\n",
    "                    videos[token.lemma_].append(d['video'])\n",
    "                    time[token.lemma_].append(time_i)\n",
    "                else:\n",
    "                    videos[token.lemma_] = [d['video']]\n",
    "                    time[token.lemma_] = [time_i]\n",
    "        didemo_nouns.update(doc_i_nouns)\n",
    "        \n",
    "with open(filename, 'x') as fid:\n",
    "    json.dump({'nouns': didemo_nouns, 'videos': videos, 'time': time}, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More fine-grained version of previous cell i.e. code repetition.\n",
    "\n",
    "- NOUNs per subset\n",
    "\n",
    "- annotation ids per NOUNs per subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "output_file = 'data/interim/didemo/nouns_to_video.json'\n",
    "# Make sure you downloaded DiDeMo data and place it in\n",
    "# data/raw/{}_data.json\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "subsets = ['train', 'val', 'test']\n",
    "num_descriptions = 0\n",
    "didemo_nouns = Counter()\n",
    "noun_counts_per_set = {i: Counter() for i in subsets}\n",
    "nouns_per_set = {i: set() for i in subsets}\n",
    "aid_per_set = {i: {} for i in subsets}\n",
    "videos = {}\n",
    "time = {}\n",
    "for subset in subsets:\n",
    "    filename = f'data/raw/{subset}_data.json'\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    for d in data:\n",
    "        num_descriptions += 1\n",
    "        d_i = d['description']\n",
    "        doc_i = nlp(d_i)\n",
    "        doc_i_nouns = Counter()\n",
    "        for token in doc_i:\n",
    "            if token.pos_ == 'NOUN':\n",
    "                doc_i_nouns.update({token.lemma_: 1})\n",
    "                nouns_per_set[subset].add(token.lemma_)\n",
    "                \n",
    "                random.shuffle(d['times'])\n",
    "                time_i = d['times'][0]\n",
    "                if token.lemma_ in videos:\n",
    "                    videos[token.lemma_].append(d['video'])\n",
    "                    time[token.lemma_].append(time_i)\n",
    "                else:\n",
    "                    videos[token.lemma_] = [d['video']]\n",
    "                    time[token.lemma_] = [time_i]\n",
    "                nouns_per_set[subset].add(token.lemma_)\n",
    "        \n",
    "        for noun in doc_i_nouns:\n",
    "            annotation_id = d['annotation_id']\n",
    "            if noun in aid_per_set[subset]:\n",
    "                aid_per_set[subset][noun].append(annotation_id)\n",
    "            else:\n",
    "                aid_per_set[subset][noun] = [annotation_id]\n",
    "                \n",
    "        noun_counts_per_set[subset].update(doc_i_nouns)\n",
    "        didemo_nouns.update(doc_i_nouns)\n",
    "\n",
    "if filename is None:\n",
    "    raise ValueError('never mind ;)')\n",
    "\n",
    "for k, v in nouns_per_set.items():\n",
    "    nouns_per_set[k] = list(v)\n",
    "with open(output_file, 'w') as fid:\n",
    "    json.dump({'nouns': didemo_nouns,\n",
    "               'videos': videos,\n",
    "               'time': time,\n",
    "               'nouns_per_subset': nouns_per_set,\n",
    "               'counts_per_subset': noun_counts_per_set,\n",
    "               'annotations_per_subset': aid_per_set}, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Test] `NOUN` extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of descriptions 41206\n",
      "\n",
      "man in maroon has left arm in air, two frames\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1800\" height=\"487.0\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">man</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">maroon</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">has</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">left</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">arm</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">air,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">two</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">frames</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M210.0,354.0 L218.0,342.0 202.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M385.0,354.0 L393.0,342.0 377.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M770,352.0 C770,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,354.0 L1098.0,342.0 1082.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1260.0,354.0 L1268.0,342.0 1252.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 1625.0,2.0 1625.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1625.0,354.0 L1633.0,342.0 1617.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man\n",
      "maroon\n",
      "arm\n",
      "air\n",
      "frame\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "SEED = None # 123\n",
    "if SEED is not None:\n",
    "    random.seed(SEED)\n",
    "\n",
    "descriptions = []\n",
    "subsets = ['train', 'val', 'test']\n",
    "for i in subsets:\n",
    "    filename = f'data/raw/{i}_data.json'\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    for d in data:\n",
    "        descriptions.append(d['description'])\n",
    "print('Number of descriptions', len(descriptions))\n",
    "\n",
    "random.shuffle(descriptions)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print()\n",
    "for d_i in descriptions:\n",
    "    doc = nlp(d_i)\n",
    "    print(d_i)\n",
    "    displacy.render(doc, style='dep', jupyter=True)\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            print(token.lemma_)\n",
    "#     for token in doc:\n",
    "#         print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#               token.shape_, token.is_alpha, token.is_stop)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outside data\n",
    "\n",
    "## YFCC100M\n",
    "\n",
    "[project](https://webscope.sandbox.yahoo.com/catalog.php?datatype=i&did=67&guccounter=1)\n",
    "\n",
    "[another description](http://riemenschneider.hayko.at/vision/dataset/task.php?did=280)\n",
    "\n",
    "data@adobe: `/mnt/ilcompf2d1/data/yfcc100m/`\n",
    "\n",
    "Branches\n",
    "\n",
    "- [Bryan's previous project](http://deep-tagging.cs.washington.edu/)\n",
    "\n",
    "    [paper about data](https://arxiv.org/pdf/1411.6909.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@escorciav attempt to parse data.\n",
    "\n",
    "He quit this approach after realizing how demanding it was and the existence of a similar endeavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "USER_TAGS = 8\n",
    "PHOTO_OR_VIDEO = 22\n",
    "\n",
    "for i in glob.glob('/mnt/ilcompf2d1/data/yfcc100m/yfcc100m_dataset-*'):\n",
    "    raise NotImplementedError('postponed')\n",
    "    df = pd.read_csv(i, delimiter='\\t', header=None)\n",
    "    idx = ((df.loc[:, PHOTO_OR_VIDEO] == 0) &\n",
    "           (pd.notna(df.loc[:, USER_TAGS])))\n",
    "    # TODO copy column of interest and append it to list\n",
    "    # df.loc[idx, USER_TAGS]\n",
    "# TODO concat all dataFrames\n",
    "\n",
    "# TODO for each row\n",
    "# parse tags with spacy to remove plurals and focus on nouns    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Website](http://deep-tagging.cs.washington.edu/imagenet_correspondence.html) from previous Bryan's work with data easy to scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Tag frequency will be dumped here\n",
    "filename = 'data/interim/yfcc100m/tag_frequency.csv'\n",
    "# Make sure that you download the website mentioned above\n",
    "# It assumes that you placed it here:\n",
    "html_file = 'data/raw/yfcc100m/tags.html'\n",
    "\n",
    "with open(html_file) as fid:\n",
    "    page = fid.read()\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "table = soup.find('div', attrs={'id':'content'}).find('tbody').find_all('tr')\n",
    "\n",
    "# Comment the last line if you are not interested in\n",
    "# dumping CSV with counts of tags\n",
    "with open(filename, 'x') as fid:\n",
    "    fid.write('tag,count\\n')\n",
    "    for row in table:\n",
    "        tag = row.find('th').text\n",
    "        frequency = row.find('svg').text\n",
    "        fid.write(f'{tag},{frequency}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging DiDeMo and YFCC100M tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags found: 951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'altair-data-41217a5eb806a0e8ca497668ef5f1003.csv',\n",
       " 'format': {'type': 'csv'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tags, rows = {}, []\n",
    "found_tags = 0\n",
    "file_ref = 'data/interim/didemo/nouns_count.csv'\n",
    "filename = 'data/interim/yfcc100m/tag_frequency.csv'\n",
    "newfile = 'data/interim/didemo/nouns_yfcc100m.csv'\n",
    "\n",
    "# Get didemo tags\n",
    "with open(file_ref) as fid:\n",
    "    i = 0\n",
    "    for line in fid:\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        tag, count = line.strip().split(',')\n",
    "        tags[tag] = None\n",
    "        rows.append({'tag': tag, 'instances': count, 'dataset': 'DiDeMo'})\n",
    "\n",
    "# Add YFCC100M tags that are in Didemo\n",
    "with open(filename) as fid:\n",
    "    i = 0\n",
    "    for line in fid:\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        tag, count = line.strip().split(',')\n",
    "        if tag in tags:\n",
    "            found_tags += 1\n",
    "            rows.append({'tag': tag, 'instances': count, 'dataset': 'YFCC100M'})\n",
    "print(f'Tags found: {found_tags}')\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "#df.to_csv(newfile, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export data to layered plot with two axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags found: 951\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tags, rows = {}, []\n",
    "found_tags = 0\n",
    "file_ref = 'data/interim/didemo/nouns_count.csv'\n",
    "filename = 'data/interim/yfcc100m/tag_frequency.csv'\n",
    "newfile = 'data/interim/didemo/nouns_didemo_vs_yfcc100m.csv'\n",
    "\n",
    "# Get didemo tags\n",
    "with open(file_ref, 'r') as fid:\n",
    "    for i, line in enumerate(fid):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        tag, count = line.strip().split(',')\n",
    "        tags[tag] = i - 1\n",
    "        rows.append({'tag': tag, 'instances_didemo': int(count)})\n",
    "\n",
    "# Add YFCC100M tags that are in Didemo\n",
    "with open(filename, 'r') as fid:\n",
    "    for i, line in enumerate(fid):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        tag, count = line.strip().split(',')\n",
    "        if tag in tags:\n",
    "            found_tags += 1\n",
    "            rows[tags[tag]]['instances_yfcc100m'] = int(count)\n",
    "print(f'Tags found: {found_tags}')\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "#df.to_csv(newfile, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot YFCC100M vs DiDeMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ind = (pd.notna(df['instances_yfcc100m']) &\n",
    "       (df.loc[:, 'instances_yfcc100m'] > df.loc[:, 'instances_didemo']))\n",
    "ind = ind.nonzero()[0]\n",
    "assert len(ind) == pd.notna(df['instances_yfcc100m']).sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(40, 10))\n",
    "df.instances_didemo.plot(kind='bar', ax=ax, color='#a6cee3')\n",
    "ax2 = df.instances_yfcc100m.plot(kind='bar', ax=ax, color='#fb9a99', secondary_y=True)\n",
    "idx = np.linspace(0, len(df) - 1, 100).astype(int)\n",
    "ax.set_xticks(idx)\n",
    "_ = ax.set_xticklabels(df.loc[idx, 'tag'], rotation=90, size=12)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_ylabel('Instances DiDeMo', size=12)\n",
    "ax2.tick_params(labelsize=12)\n",
    "# ax2.set_ylabel('Instances YFCC100M', size=12)\n",
    "#plt.savefig(\"data/interim/didemo/nouns_didemo_vs_yfcc100m.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUNs with <= to 2 instances get 238 [6.17][25.03]\n",
      "NOUNs with <= to 8 instances get 481 [12.46][50.58]\n",
      "NOUNs with <= to 31 instances get 707 [18.32][74.34]\n",
      "NOUNs with <= to 79 instances get 814 [21.09][85.59]\n",
      "NOUNs with <= to 134 instances get 866 [22.44][91.06]\n",
      "NOUNs with <= to 490 instances get 923 [23.91][97.06]\n",
      "NOUNs with <= to 6313 instances get 951 [24.64][100.00]\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values('instances_didemo', ascending=False)\n",
    "percentile = [50, 25, 10, 5, 3, 1, 1-0.99]\n",
    "lind_in_yfc100m = pd.notna(df.loc[:, 'instances_yfcc100m'])\n",
    "for i in percentile:\n",
    "    ind = int(len(df['instances_didemo']) * i / 100)\n",
    "    percentile_value = df.loc[ind, 'instances_didemo']\n",
    "    lind_below_pctile = df.loc[:, 'instances_didemo'] <= percentile_value\n",
    "    tags_below_pctile = (lind_below_pctile & lind_in_yfc100m).sum()\n",
    "    print(f'NOUNs with <= to {percentile_value} instances get {tags_below_pctile} [{100 * tags_below_pctile / len(df):.2f}][{100 * tags_below_pctile / lind_in_yfc100m.sum():.2f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate cloudword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff'] = df['instances_yfcc100m'] - df['instances_didemo']\n",
    "df2 = df.loc[lind_in_yfc100m, :].tail(n=100)\n",
    "df2.loc[:, 'instances_yfcc100m'] = 100 * df2.loc[:, 'instances_yfcc100m'].max() / df.loc[:, 'instances_yfcc100m'].max()\n",
    "ind = df2.loc[:, 'instances_yfcc100m'] < 1\n",
    "for i, row in df2.iterrows():\n",
    "    for j in range(int(row['instances_yfcc100m'])):\n",
    "        print(row['tag'], end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open images\n",
    "\n",
    "[project](https://storage.googleapis.com/openimages/web/index.html)\n",
    "\n",
    "[details](https://storage.googleapis.com/openimages/web/download.html) about annotations \n",
    "\n",
    "data at adobe\n",
    "\n",
    "all images (v1): `/mnt/ilcompf5d0/data/google_openimages`\n",
    "\n",
    "boxes: TBD\n",
    "\n",
    "image-level labels: `/mnt/ilcompf9d1/user/escorcia/image_level`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7186"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_trainable = '/mnt/ilcompf9d1/user/escorcia/openimages/image_level/classes-trainable.txt'\n",
    "file_description = '/mnt/ilcompf9d1/user/escorcia/openimages/image_level/class-descriptions.csv'\n",
    "\n",
    "trainable_df = pd.read_csv(file_trainable, header=None, columns='key')\n",
    "trainable = dict.fromkeys(trainable_df['key'].tolist())\n",
    "description_df = pd.read_csv(file_description, header=None, columns=['key', 'description'])\n",
    "len(trainable_df, )\n",
    "# Comment the last line if you are not interested in\n",
    "# dumping CSV with counts of tags\n",
    "# with open(filename, 'w') as fid:\n",
    "#     fid.write('tag,count\\n')\n",
    "#     for row in table:\n",
    "#         tag = row.find('th').text\n",
    "#         frequency = row.find('svg').text\n",
    "#         fid.write(f'{tag},{frequency}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HICO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO\n",
    "\n",
    "[project](http://cocodataset.org/#captions-2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual genome\n",
    "\n",
    "[project](http://visualgenome.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flickr30k\n",
    "\n",
    "[project](http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/)\n",
    "\n",
    "[website](http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/phraseList.html) to scrap for tags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
