{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sentence retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from model import SMCN\n",
    "from didemo import DidemoSMCN, TemporalFeatures\n",
    "\n",
    "SMCN_PRM = dict(visual_size=2048, lang_size=300, embedding_size=100,\n",
    "                dropout=0.3, max_length=50, visual_hidden=500,\n",
    "                lang_hidden=1000)\n",
    "PTH_FILE = 'data/interim/smcn_12/a/3_checkpoint.pth.tar'\n",
    "VAL_LIST_PATH = 'data/raw/val_data.json'\n",
    "RGB_FEAT_PATH = 'data/interim/didemo/resnet152/320x240_max.h5'\n",
    "args = dict(test=False, context=False, loc=TemporalFeatures.NONE, cues=dict(rgb=dict(file=RGB_FEAT_PATH)))\n",
    "\n",
    "def load_model(smcn_prm, cuda=False, filename=None):\n",
    "    model = SMCN(**smcn_prm)\n",
    "    model.eval()\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    if filename is not None:\n",
    "        snapshot = torch.load(filename)\n",
    "        model.load_state_dict(snapshot['state_dict'])\n",
    "    return model\n",
    "\n",
    "def torchify_and_collate(data, cuda=True):\n",
    "    if isinstance(data, dict):\n",
    "        if cuda:\n",
    "            return {k: torch.from_numpy(v).unsqueeze_(0).cuda()\n",
    "                    for k, v in data.items()}\n",
    "        return {k: torch.from_numpy(v).unsqueeze_(0)\n",
    "                for k, v in data.items()}\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        if cuda:\n",
    "            return torch.from_numpy(data).unsqueeze_(0).cuda()\n",
    "        return torch.from_numpy(data).unsqueeze_(0)\n",
    "    elif isinstance(data, int):\n",
    "        if cuda:\n",
    "            return torch.tensor([data]).cuda()\n",
    "        return torch.tensor([data])\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def honorable_cev(cuda):\n",
    "    torch.set_grad_enabled(False)\n",
    "    model = load_model(SMCN_PRM, filename=PTH_FILE, cuda=cuda)\n",
    "    val_dataset = DidemoSMCN(VAL_LIST_PATH, **args)\n",
    "    descriptions_rank = []\n",
    "    counter = 0\n",
    "    for moment_i_data in val_dataset:\n",
    "        # get visual representation of a moment\n",
    "        # TODO (critical): make it deterministic\n",
    "        moment_i_ind = moment_i_data[0]\n",
    "        moment_i_visual_rep = torchify_and_collate(moment_i_data[4], cuda=cuda)\n",
    "        score_wrt_all_sentences = []\n",
    "        for moment_j_data in val_dataset:\n",
    "            # get text representation of sentence\n",
    "            sentence_j_rep = torchify_and_collate(moment_j_data[2])\n",
    "            sentence_j_length = torchify_and_collate(moment_j_data[3], cuda=cuda)\n",
    "            score_j, is_similarity = model.predict(\n",
    "                sentence_j_rep, sentence_j_length, moment_i_visual_rep)\n",
    "            score_wrt_all_sentences.append(score_j)\n",
    "\n",
    "        score_wrt_all_sentences = torch.cat(score_wrt_all_sentences)\n",
    "        if not is_similarity:\n",
    "            _, ranked_ind = score_wrt_all_sentences.sort()\n",
    "            descriptions_rank.append(ranked_ind.eq(moment_i_ind).nonzero()[0, 0])\n",
    "        else:\n",
    "            NotImplementedError('WIP :P')\n",
    "\n",
    "        counter += 1\n",
    "        if counter == 10:\n",
    "            break\n",
    "    # TODO (critical): compute median and mean rank of description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is bottleneck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__  214.74 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<line_profiler.LineProfiler at 0x7f7f7734d828>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 527.86 s\n",
       "File: <ipython-input-2-3011451fa9d9>\n",
       "Function: honorable_cev at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def honorable_cev():\n",
       "     2         1         37.0     37.0      0.0      torch.set_grad_enabled(False)\n",
       "     3         1     150554.0 150554.0      0.0      model = load_model(SMCN_PRM, filename=PTH_FILE)\n",
       "     4         1  219278103.0 219278103.0     41.5      val_dataset = DidemoSMCN(VAL_LIST_PATH, **args)\n",
       "     5         1          2.0      2.0      0.0      descriptions_rank = []\n",
       "     6         1          1.0      1.0      0.0      counter = 0\n",
       "     7        10       5979.0    597.9      0.0      for moment_i_data in val_dataset:\n",
       "     8                                                   # get visual representation of a moment\n",
       "     9                                                   # TODO (critical): make it deterministic\n",
       "    10        10         14.0      1.4      0.0          moment_i_ind = moment_i_data[0]\n",
       "    11        10        407.0     40.7      0.0          moment_i_visual_rep = torchify_and_collate(moment_i_data[4])\n",
       "    12        10         19.0      1.9      0.0          score_wrt_all_sentences = []\n",
       "    13     41810   24675538.0    590.2      4.7          for moment_j_data in val_dataset:\n",
       "    14                                                       # get text representation of sentence\n",
       "    15     41800    1111620.0     26.6      0.2              sentence_j_rep = torchify_and_collate(moment_j_data[2])\n",
       "    16     41800     566045.0     13.5      0.1              sentence_j_length = torchify_and_collate(moment_j_data[3])\n",
       "    17     41800      72866.0      1.7      0.0              score_j, is_similarity = model.predict(\n",
       "    18     41800  281767123.0   6740.8     53.4                  sentence_j_rep, sentence_j_length, moment_i_visual_rep)\n",
       "    19     41800     134634.0      3.2      0.0              score_wrt_all_sentences.append(score_j)\n",
       "    20                                           \n",
       "    21        10      75935.0   7593.5      0.0          score_wrt_all_sentences = torch.cat(score_wrt_all_sentences)\n",
       "    22        10         17.0      1.7      0.0          if not is_similarity:\n",
       "    23        10      20422.0   2042.2      0.0              _, ranked_ind = score_wrt_all_sentences.sort()\n",
       "    24        10        386.0     38.6      0.0              descriptions_rank.append(ranked_ind.eq(moment_i_ind).nonzero()[0, 0])\n",
       "    25                                                   else:\n",
       "    26                                                       NotImplementedError('WIP :P')\n",
       "    27                                           \n",
       "    28        10         14.0      1.4      0.0          counter += 1\n",
       "    29        10         10.0      1.0      0.0          if counter == 10:\n",
       "    30         1          1.0      1.0      0.0              break"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -s -r -f honorable_cev honorable_cev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying bottleneck after switching to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -s -r -f honorable_cev honorable_cev(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Batched implementation\n",
    "\n",
    "TODO. It was cumbersome and we did not have time ðŸ˜“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Moment retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from model import SMCN\n",
    "from didemo import DidemoSMCNRetrieval\n",
    "from didemo import RetrievalMode, TemporalFeatures\n",
    "\n",
    "SMCN_PRM = dict(visual_size=2048, lang_size=300, embedding_size=100,\n",
    "                dropout=0.3, max_length=50, visual_hidden=500,\n",
    "                lang_hidden=1000)\n",
    "PTH_FILE = 'data/interim/smcn_12/a/3_checkpoint.pth.tar'\n",
    "VAL_LIST_PATH = 'data/raw/val_data_wwa.json'\n",
    "RGB_FEAT_PATH = 'data/interim/didemo/resnet152/320x240_max.h5'\n",
    "DATASET_PRM = dict(context=False, loc=TemporalFeatures.NONE,\n",
    "                   cues=dict(rgb=dict(file=RGB_FEAT_PATH)))\n",
    "\n",
    "def load_model(smcn_prm, cuda=False, filename=None):\n",
    "    model = SMCN(**smcn_prm)\n",
    "    model.eval()\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    if filename is not None:\n",
    "        snapshot = torch.load(filename)\n",
    "        model.load_state_dict(snapshot['state_dict'])\n",
    "    return model\n",
    "\n",
    "def torchify_and_collate(data, unsqueeze=False, cuda=False):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: torchify_and_collate(v) for k, v in data.items()}\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        output = torch.from_numpy(data)\n",
    "        if unsqueeze:\n",
    "            output.unsqueeze_(0)\n",
    "        if cuda:\n",
    "            return output.cuda()\n",
    "        return output\n",
    "    elif isinstance(data, int):\n",
    "        if cuda:\n",
    "            return torch.tensor([data]).cuda()\n",
    "        return torch.tensor([data])\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def honorable_cev(cuda):\n",
    "    torch.set_grad_enabled(False)\n",
    "    model = load_model(SMCN_PRM, cuda, PTH_FILE)\n",
    "    val_dataset = DidemoSMCNRetrieval(VAL_LIST_PATH, **DATASET_PRM)\n",
    "    # Setup prediction matrix\n",
    "    val_dataset.mode = RetrievalMode.VIDEO_TO_DESCRIPTION\n",
    "    # TODO (extension): future work once we are set with DiDeMo\n",
    "    N_s = len(val_dataset.segments)\n",
    "    N_c = len(val_dataset) * N_s\n",
    "    val_dataset.mode = RetrievalMode.DESCRIPTION_TO_MOMENT\n",
    "    M_l = len(val_dataset)\n",
    "    prediction_matrix = torch.empty(M_l, N_c)\n",
    "\n",
    "    counter = 0\n",
    "    for moment_i_data in val_dataset:\n",
    "        # get visual representation of a moment\n",
    "        moment_i_ind = moment_i_data[0]\n",
    "        sentence_i_rep = torchify_and_collate(moment_i_data[1], True, cuda)\n",
    "        sentence_i_length = torchify_and_collate(moment_i_data[2], False, cuda)\n",
    "\n",
    "        # Switch mode to iterate over phrases\n",
    "        val_dataset.mode = RetrievalMode.VIDEO_TO_DESCRIPTION\n",
    "        for video_j_data in val_dataset:\n",
    "            # get text representation of sentence\n",
    "            video_j_ind = video_j_data[0]\n",
    "            video_j_visual_rep = torchify_and_collate(video_j_data[1], False, cuda)\n",
    "            assert N_s == video_j_visual_rep['mask'].shape[0]\n",
    "            # TODO (debug): double check that predict works here\n",
    "            # 1st check, apparently we are good to go. let's try out!\n",
    "            score_ij, is_similarity = model.predict(\n",
    "                sentence_i_rep, sentence_i_length, video_j_visual_rep)\n",
    "            ind_start, ind_end = video_j_ind * N_s, (video_j_ind + 1) * N_s\n",
    "            prediction_matrix[moment_i_ind, ind_start:ind_end] = score_ij\n",
    "            # TODO (critical): block-out segments in videos without visual\n",
    "            # feature e.g. a video only has 5 chunks, similarity for the 6-th\n",
    "            # should be 0\n",
    "            # TODO (debug): hash video-id and collect them\n",
    "\n",
    "        val_dataset.mode = RetrievalMode.DESCRIPTION_TO_MOMENT\n",
    "\n",
    "        counter += 1\n",
    "        if counter == 10:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
